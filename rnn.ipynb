{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning on IBM Stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "We choose to analyse IBM history stock data which include about 13K records from the last 54 years. [From the year 1962 to this day]\n",
    "Each record contains:  \n",
    "- Open price: The price in which the market in that month started at.\n",
    "- Close price: The price in which the market in that month closed at.\n",
    "- High Price: The max price the stock reached within the month.\n",
    "- Low price: The min price the stock reached within the month.\n",
    "- Volume: The max price the stock reached within the month.\n",
    "- [Adjacent close price](https://marubozu.blogspot.co.il/2006/09/how-yahoo-calculates-adjusted-closing.html).  \n",
    "- Date: Day, Month and Year.\n",
    "\n",
    "The main challenges of this project are: \n",
    "- The limited data within a market that is changed by wide variety of things. In particular, things that we don't see in the raw data, like special accouncments on new technology.\n",
    "- The historic data of stocks in a particular situation doesn't necessarily resolve the same outcome in the exact same situation a few years later.\n",
    "- We wondered whether it is possible to actually find some features that will give us better accuracy than random.  \n",
    "\n",
    "This project is interesting because as everybody knows deep learning solved tasks that considered difficult even with pretty basic deep learning features.  \n",
    "\n",
    "\n",
    "And of course, If we find something useful when it comes to stock then good prediction = profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas_datareader.data import DataReader\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load or Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_if_not_exists(force=False):\n",
    "    if os.path.exists(\"./data/ibm.csv\") and not force:\n",
    "        return pd.read_csv(\"./data/ibm.csv\")\n",
    "    else:\n",
    "        if not os.path.exists(\"./data\"):\n",
    "            os.mkdir(\"data\")\n",
    "        ibm_data = DataReader('IBM', 'yahoo', datetime(1950, 1, 1), datetime.today())\n",
    "        pd.DataFrame(ibm_data).to_csv(\"./data/ibm.csv\")\n",
    "        return pd.DataFrame(ibm_data).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the data\n",
      "done loading the data\n"
     ]
    }
   ],
   "source": [
    "print \"loading the data\"\n",
    "data = get_data_if_not_exists(force=True)\n",
    "print \"done loading the data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data columns names: ['Date' 'Open' 'High' 'Low' 'Close' 'Volume' 'Adj Close']\n"
     ]
    }
   ],
   "source": [
    "print \"data columns names: %s\"%data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13742, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1962-01-02</td>\n",
       "      <td>578.499734</td>\n",
       "      <td>578.499734</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>387200</td>\n",
       "      <td>2.300695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1962-01-03</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>288000</td>\n",
       "      <td>2.320804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962-01-04</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>570.999742</td>\n",
       "      <td>571.250260</td>\n",
       "      <td>256000</td>\n",
       "      <td>2.297679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1962-01-05</td>\n",
       "      <td>570.500243</td>\n",
       "      <td>570.500243</td>\n",
       "      <td>558.999753</td>\n",
       "      <td>560.000253</td>\n",
       "      <td>363200</td>\n",
       "      <td>2.252429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1962-01-08</td>\n",
       "      <td>559.500003</td>\n",
       "      <td>559.500003</td>\n",
       "      <td>545.000267</td>\n",
       "      <td>549.500263</td>\n",
       "      <td>544000</td>\n",
       "      <td>2.210196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Open        High         Low       Close  Volume  \\\n",
       "0 1962-01-02  578.499734  578.499734  572.000241  572.000241  387200   \n",
       "1 1962-01-03  572.000241  576.999736  572.000241  576.999736  288000   \n",
       "2 1962-01-04  576.999736  576.999736  570.999742  571.250260  256000   \n",
       "3 1962-01-05  570.500243  570.500243  558.999753  560.000253  363200   \n",
       "4 1962-01-08  559.500003  559.500003  545.000267  549.500263  544000   \n",
       "\n",
       "   Adj Close  \n",
       "0   2.300695  \n",
       "1   2.320804  \n",
       "2   2.297679  \n",
       "3   2.252429  \n",
       "4   2.210196  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print data.shape\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data exploration highlights:\n",
    "- The data contains 13,733 records.\n",
    "- Each record reprsent one specific day.\n",
    "- Each record contain: Date, Open, High, Low, Close, Volume and Adj Close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction and Data Pre-processing.\n",
    "\n",
    "#### The features are:\n",
    "1. Open price within the day.\n",
    "1. Highest price within the day.\n",
    "1. Lowest price within the day.\n",
    "1. Close price within the day.\n",
    "1. Adj Close.\n",
    "1. Raise percentage.\n",
    "1. Spread.\n",
    "1. Up Spread.\n",
    "1. Down Spread.\n",
    "1. Absolute Difference between Close and Previous day close.\n",
    "1. Absolute Difference between Open and Previous day open.\n",
    "1. Absolute Difference between High and Previous day high.\n",
    "1. Absolute Difference between low and Previous day low.\n",
    "1. For each day we've also added a 7 previous day sliding window containing all of the above.\n",
    "1. 1 When the stock price raised for that day, 0 When the stock price didn't raise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,len(data)):\n",
    "    prev = data.iloc[i-1]\n",
    "    data.set_value(i,\"prev_close\",prev[\"Close\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[\"up/down\"] = (data[\"Close\"] - data[\"prev_close\"]) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"raise_percentage\"] = (data[\"Close\"] - data[\"prev_close\"])/data[\"prev_close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"spread\"] = abs(data[\"High\"]-data[\"Low\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"up_spread\"] = abs(data[\"High\"]-data[\"Open\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"down_spread\"] = abs(data[\"Open\"]-data[\"Low\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "for i in range(1,len(data)):\n",
    "    prev = data.iloc[i-1]\n",
    "    data.set_value(i,\"prev_open\",prev[\"Open\"])\n",
    "    data.set_value(i,\"prev_high\",prev[\"High\"])\n",
    "    data.set_value(i,\"prev_low\",prev[\"Low\"])\n",
    "#     data.set_value(i,\"month\",re.findall(\"[1-9]+\", str(data.Date[i]))[2])\n",
    "#     data.set_value(i,\"year\",re.findall(\"[1-9]+\", str(data.Date[i]))[0])\n",
    "    \n",
    "#     prev = data.iloc[i-2]\n",
    "#     data.set_value(i,\"prev_prev_open\",prev[\"Open\"])\n",
    "#     data.set_value(i,\"prev_prev_high\",prev[\"High\"])\n",
    "#     data.set_value(i,\"prev_prev_low\",prev[\"Low\"])\n",
    "#     data.set_value(i,\"prev_prev_close\",prev[\"Close\"])\n",
    "\n",
    "data[\"close_diff\"] = abs(data[\"Close\"] - data[\"prev_close\"])\n",
    "# data[\"close_diff\"] = data[\"Close\"] - data[\"prev_close\"]\n",
    "# data[\"close_diff\"] = abs(data[\"Close\"] / data[\"prev_close\"])\n",
    "data[\"open_diff\"] = abs(data[\"Open\"] - data[\"prev_open\"])\n",
    "# data[\"open_diff\"] = data[\"Open\"] - data[\"prev_open\"]\n",
    "# data[\"open_diff\"] = abs(data[\"Open\"] / data[\"prev_open\"])\n",
    "data[\"high_diff\"] = abs(data[\"High\"] - data[\"prev_high\"])\n",
    "# data[\"high_diff\"] = data[\"High\"] - data[\"prev_high\"]\n",
    "# data[\"high_diff\"] = abs(data[\"High\"] / data[\"prev_high\"])\n",
    "data[\"low_diff\"] = abs(data[\"Low\"] - data[\"prev_low\"])\n",
    "# data[\"low_diff\"] = data[\"Low\"] - data[\"prev_low\"]\n",
    "# data[\"low_diff\"] = abs(data[\"Low\"] / data[\"prev_low\"])\n",
    "\n",
    "# data[\"prev_prev_close_diff\"] = (data[\"Close\"] - data[\"prev_prev_close\"])\n",
    "# data[\"prev_prev_raise_percentage\"] = (data[\"Close\"] - data[\"prev_prev_close\"])/data[\"prev_prev_close\"]\n",
    "# data[\"prev_prev_open_diff\"] = (data[\"Open\"] - data[\"prev_prev_open\"])\n",
    "# data[\"prev_prev_high_diff\"] = (data[\"High\"] - data[\"prev_prev_high\"])\n",
    "# data[\"prev_prev_low_diff\"] = (data[\"Low\"] - data[\"prev_prev_low\"])\n",
    "# data[\"open_close_mean\"] = (data[\"Open\"] + data[\"Close\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>prev_close</th>\n",
       "      <th>raise_percentage</th>\n",
       "      <th>spread</th>\n",
       "      <th>up_spread</th>\n",
       "      <th>down_spread</th>\n",
       "      <th>prev_open</th>\n",
       "      <th>prev_high</th>\n",
       "      <th>prev_low</th>\n",
       "      <th>close_diff</th>\n",
       "      <th>open_diff</th>\n",
       "      <th>high_diff</th>\n",
       "      <th>low_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13741.000000</td>\n",
       "      <td>13741.000000</td>\n",
       "      <td>13741.000000</td>\n",
       "      <td>13741.000000</td>\n",
       "      <td>1.374100e+04</td>\n",
       "      <td>13741.000000</td>\n",
       "      <td>13741.000000</td>\n",
       "      <td>13741.000000</td>\n",
       "      <td>13741.000000</td>\n",
       "      <td>13741.000000</td>\n",
       "      <td>13741.000000</td>\n",
       "      <td>13741.000000</td>\n",
       "      <td>13741.000000</td>\n",
       "      <td>13741.000000</td>\n",
       "      <td>13741.000000</td>\n",
       "      <td>13741.000000</td>\n",
       "      <td>13741.000000</td>\n",
       "      <td>13741.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>190.008158</td>\n",
       "      <td>191.603641</td>\n",
       "      <td>188.511639</td>\n",
       "      <td>190.033304</td>\n",
       "      <td>4.887131e+06</td>\n",
       "      <td>42.262355</td>\n",
       "      <td>190.063239</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>3.092003</td>\n",
       "      <td>1.595484</td>\n",
       "      <td>1.496519</td>\n",
       "      <td>190.038605</td>\n",
       "      <td>191.634035</td>\n",
       "      <td>188.541637</td>\n",
       "      <td>2.015429</td>\n",
       "      <td>1.945130</td>\n",
       "      <td>1.743916</td>\n",
       "      <td>1.821492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>132.087441</td>\n",
       "      <td>132.872340</td>\n",
       "      <td>131.418096</td>\n",
       "      <td>132.095695</td>\n",
       "      <td>4.577546e+06</td>\n",
       "      <td>51.494861</td>\n",
       "      <td>132.135641</td>\n",
       "      <td>0.019016</td>\n",
       "      <td>2.524495</td>\n",
       "      <td>1.926574</td>\n",
       "      <td>1.955207</td>\n",
       "      <td>132.128765</td>\n",
       "      <td>132.913067</td>\n",
       "      <td>131.458581</td>\n",
       "      <td>4.574082</td>\n",
       "      <td>4.469844</td>\n",
       "      <td>4.481142</td>\n",
       "      <td>4.526188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>40.625000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.231153</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-0.749178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>40.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>97.519997</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>1.182400e+06</td>\n",
       "      <td>5.944442</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>-0.007973</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.270004</td>\n",
       "      <td>97.519997</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.379997</td>\n",
       "      <td>0.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>128.125000</td>\n",
       "      <td>129.250000</td>\n",
       "      <td>127.199997</td>\n",
       "      <td>128.250000</td>\n",
       "      <td>4.168400e+06</td>\n",
       "      <td>16.215748</td>\n",
       "      <td>128.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>128.125000</td>\n",
       "      <td>129.250000</td>\n",
       "      <td>127.199997</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>263.750092</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>261.750092</td>\n",
       "      <td>263.750092</td>\n",
       "      <td>6.963100e+06</td>\n",
       "      <td>71.161487</td>\n",
       "      <td>263.875008</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>3.875046</td>\n",
       "      <td>2.029999</td>\n",
       "      <td>1.999498</td>\n",
       "      <td>263.750092</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>261.750092</td>\n",
       "      <td>2.499848</td>\n",
       "      <td>2.375046</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>2.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>649.000015</td>\n",
       "      <td>649.874802</td>\n",
       "      <td>645.500031</td>\n",
       "      <td>649.000015</td>\n",
       "      <td>6.944470e+07</td>\n",
       "      <td>197.047189</td>\n",
       "      <td>649.000015</td>\n",
       "      <td>0.131636</td>\n",
       "      <td>42.000031</td>\n",
       "      <td>28.500009</td>\n",
       "      <td>42.000031</td>\n",
       "      <td>649.000015</td>\n",
       "      <td>649.874802</td>\n",
       "      <td>645.500031</td>\n",
       "      <td>308.499985</td>\n",
       "      <td>309.000015</td>\n",
       "      <td>311.500015</td>\n",
       "      <td>312.999992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open          High           Low         Close        Volume  \\\n",
       "count  13741.000000  13741.000000  13741.000000  13741.000000  1.374100e+04   \n",
       "mean     190.008158    191.603641    188.511639    190.033304  4.887131e+06   \n",
       "std      132.087441    132.872340    131.418096    132.095695  4.577546e+06   \n",
       "min       41.000000     41.750000     40.625000     41.000000  0.000000e+00   \n",
       "25%       97.519997     98.500000     96.500000     97.500000  1.182400e+06   \n",
       "50%      128.125000    129.250000    127.199997    128.250000  4.168400e+06   \n",
       "75%      263.750092    266.000000    261.750092    263.750092  6.963100e+06   \n",
       "max      649.000015    649.874802    645.500031    649.000015  6.944470e+07   \n",
       "\n",
       "          Adj Close    prev_close  raise_percentage        spread  \\\n",
       "count  13741.000000  13741.000000      13741.000000  13741.000000   \n",
       "mean      42.262355    190.063239          0.000130      3.092003   \n",
       "std       51.494861    132.135641          0.019016      2.524495   \n",
       "min        1.231153     41.000000         -0.749178      0.000000   \n",
       "25%        5.944442     97.500000         -0.007973      1.500000   \n",
       "50%       16.215748    128.250000          0.000000      2.375000   \n",
       "75%       71.161487    263.875008          0.008315      3.875046   \n",
       "max      197.047189    649.000015          0.131636     42.000031   \n",
       "\n",
       "          up_spread   down_spread     prev_open     prev_high      prev_low  \\\n",
       "count  13741.000000  13741.000000  13741.000000  13741.000000  13741.000000   \n",
       "mean       1.595484      1.496519    190.038605    191.634035    188.541637   \n",
       "std        1.926574      1.955207    132.128765    132.913067    131.458581   \n",
       "min        0.000000      0.000000     41.000000     41.750000     40.625000   \n",
       "25%        0.375000      0.270004     97.519997     98.500000     96.500000   \n",
       "50%        1.000000      0.875000    128.125000    129.250000    127.199997   \n",
       "75%        2.029999      1.999498    263.750092    266.000000    261.750092   \n",
       "max       28.500009     42.000031    649.000015    649.874802    645.500031   \n",
       "\n",
       "         close_diff     open_diff     high_diff      low_diff  \n",
       "count  13741.000000  13741.000000  13741.000000  13741.000000  \n",
       "mean       2.015429      1.945130      1.743916      1.821492  \n",
       "std        4.574082      4.469844      4.481142      4.526188  \n",
       "min        0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.500000      0.500000      0.379997      0.400002  \n",
       "50%        1.180000      1.125000      1.000000      1.000000  \n",
       "75%        2.499848      2.375046      2.062500      2.187500  \n",
       "max      308.499985    309.000015    311.500015    312.999992  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing the first record because have no previuse record therefore can't know if up or down\n",
    "data = data[1:]\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_WINDOW = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(items):\n",
    "    return [[item[1], item[2], item[3], item[4],\n",
    "            item[5], item[6], item[9], item[10],\n",
    "            item[11], item[12], item[16], item[17],\n",
    "            item[18], item[19], 1] \n",
    "            \n",
    "            if item[8] \n",
    "            \n",
    "            else \n",
    "           [item[1], item[2], item[3], item[4],\n",
    "            item[5], item[6], item[9], item[10],\n",
    "            item[11], item[12], item[16], item[17],\n",
    "            item[18], item[19], 0] \n",
    "            \n",
    "            for item in items]\n",
    "                \n",
    "\n",
    "# def extract_features(items):\n",
    "#     return [[item[12],item[11],item[10],item[9], 1] if item[8] else [item[12],item[11],item[10],item[9], -1] for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_expected_result(item):\n",
    "    return 1 if item[8] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_input_and_outputs(data,extractFeaturesFunc=extract_features,expectedResultFunc=extract_expected_result):\n",
    "    step = 1\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for i in range(0, len(data) - MAX_WINDOW, step):\n",
    "        inputs.append(extractFeaturesFunc(data.iloc[i:i + MAX_WINDOW].as_matrix()))\n",
    "        outputs.append(expectedResultFunc(data.iloc[i + MAX_WINDOW].as_matrix()))\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating model input and outputs\n",
      "done generating input and outputs\n"
     ]
    }
   ],
   "source": [
    "print \"generating model input and outputs\"\n",
    "X, y = generate_input_and_outputs(data)\n",
    "print \"done generating input and outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_validation,y_train,y_validation = train_test_split(X_train,y_train,test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration of the deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_output_size1 = 128\n",
    "layer_output_size2 = 128\n",
    "output_classes = len(y[0])\n",
    "percentage_of_neurons_to_ignore = 0.2\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(layer_output_size1, return_sequences=True, input_shape=(MAX_WINDOW, len(X[0][0]))))\n",
    "model.add(Dropout(percentage_of_neurons_to_ignore))\n",
    "model.add(LSTM(layer_output_size2, return_sequences=False))\n",
    "model.add(Dropout(percentage_of_neurons_to_ignore))\n",
    "model.add(Dense(output_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.alg_name = \"LSTM\"\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='rmsprop')\n",
    "models.append(model)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(layer_output_size1, return_sequences=True, input_shape=(MAX_WINDOW, len(X[0][0]))))\n",
    "model.add(Dropout(percentage_of_neurons_to_ignore))\n",
    "model.add(SimpleRNN(layer_output_size2, return_sequences=False))\n",
    "model.add(Dropout(percentage_of_neurons_to_ignore))\n",
    "model.add(Dense(output_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.alg_name = \"SimpleRNN\"\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='rmsprop')\n",
    "models.append(model)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(layer_output_size1, return_sequences=True, input_shape=(MAX_WINDOW, len(X[0][0]))))\n",
    "model.add(Dropout(percentage_of_neurons_to_ignore))\n",
    "model.add(GRU(layer_output_size2, return_sequences=False))\n",
    "model.add(Dropout(percentage_of_neurons_to_ignore))\n",
    "model.add(Dense(output_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.alg_name = \"GRU\"\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='rmsprop')\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainModel(model):\n",
    "    epochs = 5\n",
    "    print \"Training model %s\"%(model.alg_name)\n",
    "    model.fit(X_train, y_train, batch_size=128, nb_epoch=epochs,validation_data=(X_validation,y_validation), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def createSplit(model):\n",
    "    print 'Adding layer of DecisionTreeClassifier'\n",
    "#     split_model = RandomForestClassifier()\n",
    "#     split_model.fit(model.predict(X_validation), y_validation)\n",
    "    \n",
    "#     split_model = ExtraTreesClassifier(n_estimators=15, max_depth=None, min_samples_split=2, random_state=0)\n",
    "#     split_model.fit(model.predict(X_validation), y_validation)\n",
    "    \n",
    "#     split_model = DecisionTreeClassifier(max_depth=None, min_samples_split=1, random_state=0)\n",
    "#     split_model.fit(model.predict(X_validation), y_validation)\n",
    "    \n",
    "    split_model = DecisionTreeClassifier()\n",
    "    split_model.fit(model.predict(X_validation), y_validation)\n",
    "    return split_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probabilities_to_prediction(record):\n",
    "    return [1,0] if record[0]>record[1] else [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluateModel(model):\n",
    "    success, success2 = 0,0\n",
    "    predicts = model.predict(X_test)\n",
    "    split_model = createSplit(model)\n",
    "    for index, record in enumerate(predicts):\n",
    "        predicted = list(split_model.predict([np.array(record)])[0])\n",
    "        predicted2 = probabilities_to_prediction(record)\n",
    "        expected = y_test[index]\n",
    "        if predicted[0] == expected[0]:\n",
    "            success += 1\n",
    "        if predicted2[0] == expected[0]:\n",
    "            success2 += 1\n",
    "    accuracy = float(success) / len(predicts)\n",
    "    accuracy2 = float(success2) / len(predicts)\n",
    "    print \"The Accuracy for %s is: %s\" % (model.alg_name, max(accuracy2, accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate():\n",
    "    accuracies = {}\n",
    "    for model in models:\n",
    "        trainModel(model)\n",
    "        acc = evaluateModel(model)\n",
    "        if model.alg_name not in accuracies:\n",
    "            accuracies[model.alg_name] = []\n",
    "        accuracies[model.alg_name].append(acc)\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model LSTM\n",
      "Adding layer of DecisionTreeClassifier\n",
      "The Accuracy for LSTM is: 0.52572815534\n",
      "Training model SimpleRNN\n",
      "Adding layer of DecisionTreeClassifier\n",
      "The Accuracy for SimpleRNN is: 0.526213592233\n",
      "Training model GRU\n",
      "Adding layer of DecisionTreeClassifier\n",
      "The Accuracy for GRU is: 0.52572815534\n"
     ]
    }
   ],
   "source": [
    "acc = train_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive algorithm:\n",
    "\n",
    "We'll choose the most frequent up / down of the stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent is: False\n",
      "The accuracy of naive algorithm is:  0.51303524614\n"
     ]
    }
   ],
   "source": [
    "all_data = data[\"up/down\"].count()\n",
    "most_frequent = data[\"up/down\"].describe().top\n",
    "frequency = data[\"up/down\"].describe().freq\n",
    "acc = float(frequency) / all_data\n",
    "\n",
    "print 'The most frequent is: %s' % (most_frequent) \n",
    "print 'The accuracy of naive algorithm is: ', acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Evaluation analysis:\n",
    "\n",
    "#### Evaluation process:\n",
    "Our evaluation used two different configurations:\n",
    "1. Raw Deep-Learning algorithm.\n",
    "1. Deep-Learning algorithm With added layer of DecisionTreeClassifier.\n",
    "\n",
    "In both cases we used the predictions of the algorithm to create a sequence to tell us whether the stock is going to get up or down. Then we checked it with the actual data and calculated accuracy.\n",
    "\n",
    "### Results:\n",
    "The accuracy as stated above is better then a naive algorithm, Not by far, But still better which means that if we follow the algorithm we are actually expected to make profit.\n",
    "\n",
    "### What next?\n",
    "As expected it seems like the raw stock data isn't get a high estimation of the stock behavior.\n",
    "We could try mixing it with information from financial articles and news,  try to take into account related stocks like the sector, S&P500 and  new features,  even checking for a country specific economics laws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Creating sequence of close price from the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features2(items):\n",
    "    return [[item[4]] for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_expected_result2(item):\n",
    "    return [item[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_WINDOW = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(data, test_size=0.1):\n",
    "    \"\"\"\n",
    "    This just splits data to training and testing parts\n",
    "    \"\"\"\n",
    "    ntrn = int(round(len(data) * (1 - test_size)))\n",
    "    X, y = generate_input_and_outputs(data,extract_features2,extract_expected_result2)\n",
    "    X_train,y_train,X_test, y_test = X[:ntrn],y[:ntrn],X[ntrn:],y[ntrn:]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train,y_train, X_test, y_test = train_test_split(data,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_output_size1 = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(layer_output_size1, return_sequences=False, input_shape=(MAX_WINDOW, len(X[0][0]))))\n",
    "model.add(Dense(len(y[0]), input_dim=layer_output_size1))\n",
    "model.add(Activation(\"linear\"))\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9928 samples, validate on 1752 samples\n",
      "Epoch 1/300\n",
      "9928/9928 [==============================] - 3s - loss: 2559.5334 - val_loss: 2.2124\n",
      "Epoch 2/300\n",
      "9928/9928 [==============================] - 2s - loss: 2528.4861 - val_loss: 6.9209\n",
      "Epoch 3/300\n",
      "9928/9928 [==============================] - 2s - loss: 2498.9034 - val_loss: 2.2409\n",
      "Epoch 4/300\n",
      "9928/9928 [==============================] - 2s - loss: 2467.1285 - val_loss: 3.5810\n",
      "Epoch 5/300\n",
      "9928/9928 [==============================] - 2s - loss: 2435.1240 - val_loss: 5.8971\n",
      "Epoch 6/300\n",
      "9928/9928 [==============================] - 2s - loss: 2405.7564 - val_loss: 3.1488\n",
      "Epoch 7/300\n",
      "9928/9928 [==============================] - 2s - loss: 2374.8461 - val_loss: 2.7618\n",
      "Epoch 8/300\n",
      "9928/9928 [==============================] - 2s - loss: 2344.0779 - val_loss: 2.0936\n",
      "Epoch 9/300\n",
      "9928/9928 [==============================] - 2s - loss: 2313.9590 - val_loss: 2.4264\n",
      "Epoch 10/300\n",
      "9928/9928 [==============================] - 2s - loss: 2287.5917 - val_loss: 2.1101\n",
      "Epoch 11/300\n",
      "9928/9928 [==============================] - 3s - loss: 2257.8772 - val_loss: 2.0266\n",
      "Epoch 12/300\n",
      "9928/9928 [==============================] - 2s - loss: 2228.0158 - val_loss: 2.0288\n",
      "Epoch 13/300\n",
      "9928/9928 [==============================] - 2s - loss: 2198.4568 - val_loss: 10.2630\n",
      "Epoch 14/300\n",
      "9928/9928 [==============================] - 2s - loss: 2171.1261 - val_loss: 5.7629\n",
      "Epoch 15/300\n",
      "9928/9928 [==============================] - 2s - loss: 2142.5621 - val_loss: 6.7474\n",
      "Epoch 16/300\n",
      "9928/9928 [==============================] - 2s - loss: 2116.6464 - val_loss: 2.6126\n",
      "Epoch 17/300\n",
      "9928/9928 [==============================] - 2s - loss: 2087.9119 - val_loss: 3.2608\n",
      "Epoch 18/300\n",
      "9928/9928 [==============================] - 2s - loss: 2062.3633 - val_loss: 3.9950\n",
      "Epoch 19/300\n",
      "9928/9928 [==============================] - 3s - loss: 2034.0267 - val_loss: 3.3293\n",
      "Epoch 20/300\n",
      "9928/9928 [==============================] - 2s - loss: 2007.8042 - val_loss: 2.4139\n",
      "Epoch 21/300\n",
      "9928/9928 [==============================] - 2s - loss: 1980.7444 - val_loss: 2.2054\n",
      "Epoch 22/300\n",
      "9928/9928 [==============================] - 2s - loss: 1957.7272 - val_loss: 2.3957\n",
      "Epoch 23/300\n",
      "9928/9928 [==============================] - 2s - loss: 1930.1734 - val_loss: 2.7049\n",
      "Epoch 24/300\n",
      "9928/9928 [==============================] - 2s - loss: 1904.5464 - val_loss: 2.3036\n",
      "Epoch 25/300\n",
      "9928/9928 [==============================] - 2s - loss: 1878.3949 - val_loss: 2.8879\n",
      "Epoch 26/300\n",
      "9928/9928 [==============================] - 2s - loss: 1853.4601 - val_loss: 2.3216\n",
      "Epoch 27/300\n",
      "9928/9928 [==============================] - 2s - loss: 1829.6243 - val_loss: 6.6703\n",
      "Epoch 28/300\n",
      "9928/9928 [==============================] - 2s - loss: 1805.8853 - val_loss: 3.4367\n",
      "Epoch 29/300\n",
      "9928/9928 [==============================] - 2s - loss: 1783.4415 - val_loss: 5.0468\n",
      "Epoch 30/300\n",
      "9928/9928 [==============================] - 2s - loss: 1755.3849 - val_loss: 5.1071\n",
      "Epoch 31/300\n",
      "9928/9928 [==============================] - 2s - loss: 1735.4918 - val_loss: 4.3528\n",
      "Epoch 32/300\n",
      "9928/9928 [==============================] - 2s - loss: 1711.0101 - val_loss: 2.7425\n",
      "Epoch 33/300\n",
      "9928/9928 [==============================] - 2s - loss: 1685.8954 - val_loss: 2.6748\n",
      "Epoch 34/300\n",
      "9928/9928 [==============================] - 2s - loss: 1663.2568 - val_loss: 2.3004\n",
      "Epoch 35/300\n",
      "9928/9928 [==============================] - 2s - loss: 1640.7987 - val_loss: 5.3765\n",
      "Epoch 36/300\n",
      "9928/9928 [==============================] - 2s - loss: 1620.5476 - val_loss: 2.7266\n",
      "Epoch 37/300\n",
      "9928/9928 [==============================] - 2s - loss: 1598.1014 - val_loss: 6.3999\n",
      "Epoch 38/300\n",
      "9928/9928 [==============================] - 2s - loss: 1575.4229 - val_loss: 5.9260\n",
      "Epoch 39/300\n",
      "9928/9928 [==============================] - 2s - loss: 1552.6844 - val_loss: 7.9895\n",
      "Epoch 40/300\n",
      "9928/9928 [==============================] - 2s - loss: 1533.6425 - val_loss: 2.4231\n",
      "Epoch 41/300\n",
      "9928/9928 [==============================] - 2s - loss: 1504.5548 - val_loss: 8.6461\n",
      "Epoch 42/300\n",
      "9928/9928 [==============================] - 2s - loss: 1492.0599 - val_loss: 4.4484\n",
      "Epoch 43/300\n",
      "9928/9928 [==============================] - 2s - loss: 1468.9806 - val_loss: 2.3626\n",
      "Epoch 44/300\n",
      "9928/9928 [==============================] - 3s - loss: 1448.7902 - val_loss: 2.3529\n",
      "Epoch 45/300\n",
      "9928/9928 [==============================] - 4s - loss: 1427.1193 - val_loss: 4.2900\n",
      "Epoch 46/300\n",
      "9928/9928 [==============================] - 3s - loss: 1408.2067 - val_loss: 6.6111\n",
      "Epoch 47/300\n",
      "9928/9928 [==============================] - 3s - loss: 1384.4850 - val_loss: 16.7467\n",
      "Epoch 48/300\n",
      "9928/9928 [==============================] - 3s - loss: 1367.3304 - val_loss: 2.3002\n",
      "Epoch 49/300\n",
      "9928/9928 [==============================] - 2s - loss: 1347.9134 - val_loss: 3.1358\n",
      "Epoch 50/300\n",
      "9928/9928 [==============================] - 2s - loss: 1330.6770 - val_loss: 5.0997\n",
      "Epoch 51/300\n",
      "9928/9928 [==============================] - 2s - loss: 1310.3084 - val_loss: 3.9316\n",
      "Epoch 52/300\n",
      "9928/9928 [==============================] - 2s - loss: 1291.0056 - val_loss: 5.8598\n",
      "Epoch 53/300\n",
      "9928/9928 [==============================] - 2s - loss: 1273.1586 - val_loss: 2.8436\n",
      "Epoch 54/300\n",
      "9928/9928 [==============================] - 2s - loss: 1252.5703 - val_loss: 2.0741\n",
      "Epoch 55/300\n",
      "9928/9928 [==============================] - 2s - loss: 1237.5039 - val_loss: 2.3774\n",
      "Epoch 56/300\n",
      "9928/9928 [==============================] - 2s - loss: 1217.8587 - val_loss: 2.6058\n",
      "Epoch 57/300\n",
      "9928/9928 [==============================] - 2s - loss: 1198.5968 - val_loss: 2.6441\n",
      "Epoch 58/300\n",
      "9928/9928 [==============================] - 2s - loss: 1182.1052 - val_loss: 2.0855\n",
      "Epoch 59/300\n",
      "9928/9928 [==============================] - 2s - loss: 1166.7834 - val_loss: 2.3675\n",
      "Epoch 60/300\n",
      "9928/9928 [==============================] - 2s - loss: 1147.9037 - val_loss: 5.9786\n",
      "Epoch 61/300\n",
      "9928/9928 [==============================] - 2s - loss: 1132.2459 - val_loss: 3.1425\n",
      "Epoch 62/300\n",
      "9928/9928 [==============================] - 2s - loss: 1114.1799 - val_loss: 5.2657\n",
      "Epoch 63/300\n",
      "9928/9928 [==============================] - 2s - loss: 1098.6272 - val_loss: 5.3194\n",
      "Epoch 64/300\n",
      "9928/9928 [==============================] - 2s - loss: 1081.7405 - val_loss: 7.1470\n",
      "Epoch 65/300\n",
      "9928/9928 [==============================] - 2s - loss: 1063.8518 - val_loss: 2.7660\n",
      "Epoch 66/300\n",
      "9928/9928 [==============================] - 2s - loss: 1049.0612 - val_loss: 4.9248\n",
      "Epoch 67/300\n",
      "9928/9928 [==============================] - 3s - loss: 1036.2556 - val_loss: 1.9640\n",
      "Epoch 68/300\n",
      "9928/9928 [==============================] - 2s - loss: 1019.4114 - val_loss: 3.2093\n",
      "Epoch 69/300\n",
      "9928/9928 [==============================] - 2s - loss: 1003.2712 - val_loss: 2.7824\n",
      "Epoch 70/300\n",
      "9928/9928 [==============================] - 2s - loss: 987.4705 - val_loss: 7.7726\n",
      "Epoch 71/300\n",
      "9928/9928 [==============================] - 2s - loss: 974.2686 - val_loss: 3.0115\n",
      "Epoch 72/300\n",
      "9928/9928 [==============================] - 2s - loss: 958.6506 - val_loss: 3.4754\n",
      "Epoch 73/300\n",
      "9928/9928 [==============================] - 3s - loss: 944.6447 - val_loss: 3.4271\n",
      "Epoch 74/300\n",
      "9928/9928 [==============================] - 3s - loss: 930.3895 - val_loss: 2.6644\n",
      "Epoch 75/300\n",
      "9928/9928 [==============================] - 2s - loss: 915.5368 - val_loss: 4.5820\n",
      "Epoch 76/300\n",
      "9928/9928 [==============================] - 2s - loss: 901.9359 - val_loss: 2.9619\n",
      "Epoch 77/300\n",
      "9928/9928 [==============================] - 3s - loss: 888.3006 - val_loss: 2.2231\n",
      "Epoch 78/300\n",
      "9928/9928 [==============================] - 2s - loss: 873.7090 - val_loss: 3.1980\n",
      "Epoch 79/300\n",
      "9928/9928 [==============================] - 2s - loss: 860.8856 - val_loss: 6.2895\n",
      "Epoch 80/300\n",
      "9928/9928 [==============================] - 2s - loss: 846.9228 - val_loss: 3.0121\n",
      "Epoch 81/300\n",
      "9928/9928 [==============================] - 2s - loss: 836.8108 - val_loss: 2.7847\n",
      "Epoch 82/300\n",
      "9928/9928 [==============================] - 2s - loss: 824.1938 - val_loss: 3.2595\n",
      "Epoch 83/300\n",
      "9928/9928 [==============================] - 2s - loss: 810.6897 - val_loss: 4.4227\n",
      "Epoch 84/300\n",
      "9928/9928 [==============================] - 2s - loss: 797.4394 - val_loss: 4.9338\n",
      "Epoch 85/300\n",
      "9928/9928 [==============================] - 2s - loss: 784.6821 - val_loss: 5.5366\n",
      "Epoch 86/300\n",
      "9928/9928 [==============================] - 3s - loss: 773.4511 - val_loss: 2.3910\n",
      "Epoch 87/300\n",
      "9928/9928 [==============================] - 2s - loss: 759.3559 - val_loss: 5.4450\n",
      "Epoch 88/300\n",
      "9928/9928 [==============================] - 3s - loss: 749.8367 - val_loss: 2.3522\n",
      "Epoch 89/300\n",
      "9928/9928 [==============================] - 2s - loss: 736.1298 - val_loss: 4.2563\n",
      "Epoch 90/300\n",
      "9928/9928 [==============================] - 2s - loss: 724.5749 - val_loss: 7.5113\n",
      "Epoch 91/300\n",
      "9928/9928 [==============================] - 2s - loss: 712.4729 - val_loss: 5.6503\n",
      "Epoch 92/300\n",
      "9928/9928 [==============================] - 2s - loss: 701.4459 - val_loss: 2.8742\n",
      "Epoch 93/300\n",
      "9928/9928 [==============================] - 2s - loss: 688.6786 - val_loss: 2.3031\n",
      "Epoch 94/300\n",
      "9928/9928 [==============================] - 2s - loss: 683.1028 - val_loss: 2.1628\n",
      "Epoch 95/300\n",
      "9928/9928 [==============================] - 2s - loss: 669.0700 - val_loss: 4.8752\n",
      "Epoch 96/300\n",
      "9928/9928 [==============================] - 2s - loss: 658.9825 - val_loss: 2.3583\n",
      "Epoch 97/300\n",
      "9928/9928 [==============================] - 2s - loss: 648.3008 - val_loss: 2.0333\n",
      "Epoch 98/300\n",
      "9928/9928 [==============================] - 2s - loss: 638.9755 - val_loss: 2.9599\n",
      "Epoch 99/300\n",
      "9928/9928 [==============================] - 2s - loss: 628.4269 - val_loss: 2.1937\n",
      "Epoch 100/300\n",
      "9928/9928 [==============================] - 2s - loss: 616.6820 - val_loss: 2.5322\n",
      "Epoch 101/300\n",
      "9928/9928 [==============================] - 2s - loss: 607.0780 - val_loss: 3.1017\n",
      "Epoch 102/300\n",
      "9928/9928 [==============================] - 2s - loss: 598.5328 - val_loss: 8.5412\n",
      "Epoch 103/300\n",
      "9928/9928 [==============================] - 2s - loss: 587.7990 - val_loss: 3.2250\n",
      "Epoch 104/300\n",
      "9928/9928 [==============================] - 2s - loss: 580.7352 - val_loss: 2.4341\n",
      "Epoch 105/300\n",
      "9928/9928 [==============================] - 2s - loss: 572.1744 - val_loss: 2.7167\n",
      "Epoch 106/300\n",
      "9928/9928 [==============================] - 2s - loss: 560.8330 - val_loss: 8.4795\n",
      "Epoch 107/300\n",
      "9928/9928 [==============================] - 4s - loss: 550.7226 - val_loss: 11.5439\n",
      "Epoch 108/300\n",
      "9928/9928 [==============================] - 4s - loss: 544.7219 - val_loss: 6.3972\n",
      "Epoch 109/300\n",
      "9928/9928 [==============================] - 4s - loss: 533.8281 - val_loss: 3.3074\n",
      "Epoch 110/300\n",
      "9928/9928 [==============================] - 4s - loss: 528.2656 - val_loss: 4.8095\n",
      "Epoch 111/300\n",
      "9928/9928 [==============================] - 4s - loss: 518.1871 - val_loss: 4.1733\n",
      "Epoch 112/300\n",
      "9928/9928 [==============================] - 4s - loss: 512.9754 - val_loss: 2.6227\n",
      "Epoch 113/300\n",
      "9928/9928 [==============================] - 4s - loss: 504.0760 - val_loss: 2.2557\n",
      "Epoch 114/300\n",
      "9928/9928 [==============================] - 4s - loss: 495.1961 - val_loss: 3.1932\n",
      "Epoch 115/300\n",
      "9928/9928 [==============================] - 4s - loss: 485.8902 - val_loss: 3.6614\n",
      "Epoch 116/300\n",
      "9928/9928 [==============================] - 4s - loss: 476.3082 - val_loss: 3.3647\n",
      "Epoch 117/300\n",
      "9928/9928 [==============================] - 4s - loss: 474.0135 - val_loss: 2.7053\n",
      "Epoch 118/300\n",
      "9928/9928 [==============================] - 4s - loss: 465.6172 - val_loss: 2.7870\n",
      "Epoch 119/300\n",
      "9928/9928 [==============================] - 4s - loss: 455.4764 - val_loss: 4.7557\n",
      "Epoch 120/300\n",
      "9928/9928 [==============================] - 4s - loss: 448.9170 - val_loss: 8.7397\n",
      "Epoch 121/300\n",
      "9928/9928 [==============================] - 4s - loss: 442.7838 - val_loss: 2.7325\n",
      "Epoch 122/300\n",
      "9928/9928 [==============================] - 4s - loss: 432.8387 - val_loss: 8.4744\n",
      "Epoch 123/300\n",
      "9928/9928 [==============================] - 4s - loss: 429.9825 - val_loss: 2.7275\n",
      "Epoch 124/300\n",
      "9928/9928 [==============================] - 4s - loss: 419.5654 - val_loss: 3.4960\n",
      "Epoch 125/300\n",
      "9928/9928 [==============================] - 4s - loss: 412.9468 - val_loss: 3.3664\n",
      "Epoch 126/300\n",
      "9928/9928 [==============================] - 4s - loss: 407.5399 - val_loss: 4.2919\n",
      "Epoch 127/300\n",
      "9928/9928 [==============================] - 4s - loss: 401.9558 - val_loss: 8.4431\n",
      "Epoch 128/300\n",
      "9928/9928 [==============================] - 4s - loss: 398.1732 - val_loss: 3.5454\n",
      "Epoch 129/300\n",
      "9928/9928 [==============================] - 4s - loss: 385.8442 - val_loss: 2.3172\n",
      "Epoch 130/300\n",
      "9928/9928 [==============================] - 4s - loss: 381.9725 - val_loss: 3.9635\n",
      "Epoch 131/300\n",
      "9928/9928 [==============================] - 4s - loss: 376.8616 - val_loss: 2.2520\n",
      "Epoch 132/300\n",
      "9928/9928 [==============================] - 4s - loss: 370.6434 - val_loss: 8.4581\n",
      "Epoch 133/300\n",
      "9928/9928 [==============================] - 4s - loss: 362.5106 - val_loss: 11.4783\n",
      "Epoch 134/300\n",
      "9928/9928 [==============================] - 4s - loss: 358.1184 - val_loss: 4.1669\n",
      "Epoch 135/300\n",
      "9928/9928 [==============================] - 4s - loss: 356.3946 - val_loss: 6.5596\n",
      "Epoch 136/300\n",
      "9928/9928 [==============================] - 3s - loss: 349.6688 - val_loss: 4.0460\n",
      "Epoch 137/300\n",
      "9928/9928 [==============================] - 4s - loss: 344.3634 - val_loss: 2.4981\n",
      "Epoch 138/300\n",
      "9928/9928 [==============================] - 4s - loss: 334.7179 - val_loss: 4.5296\n",
      "Epoch 139/300\n",
      "9928/9928 [==============================] - 4s - loss: 329.0141 - val_loss: 6.5727\n",
      "Epoch 140/300\n",
      "9928/9928 [==============================] - 4s - loss: 326.0613 - val_loss: 6.2737\n",
      "Epoch 141/300\n",
      "9928/9928 [==============================] - 4s - loss: 320.1077 - val_loss: 8.0266\n",
      "Epoch 142/300\n",
      "9928/9928 [==============================] - 4s - loss: 316.0463 - val_loss: 2.5499\n",
      "Epoch 143/300\n",
      "9928/9928 [==============================] - 4s - loss: 314.4737 - val_loss: 5.1653\n",
      "Epoch 144/300\n",
      "9928/9928 [==============================] - 4s - loss: 306.0049 - val_loss: 2.5818\n",
      "Epoch 145/300\n",
      "9928/9928 [==============================] - 4s - loss: 302.1525 - val_loss: 4.6230\n",
      "Epoch 146/300\n",
      "9928/9928 [==============================] - 4s - loss: 298.9537 - val_loss: 2.6965\n",
      "Epoch 147/300\n",
      "9928/9928 [==============================] - 4s - loss: 292.9038 - val_loss: 2.3298\n",
      "Epoch 148/300\n",
      "9928/9928 [==============================] - 4s - loss: 286.9818 - val_loss: 2.2739\n",
      "Epoch 149/300\n",
      "9928/9928 [==============================] - 2s - loss: 283.6188 - val_loss: 4.0367\n",
      "Epoch 150/300\n",
      "9928/9928 [==============================] - 2s - loss: 281.1754 - val_loss: 2.4759\n",
      "Epoch 151/300\n",
      "9928/9928 [==============================] - 2s - loss: 276.5082 - val_loss: 2.7680\n",
      "Epoch 152/300\n",
      "9928/9928 [==============================] - 2s - loss: 271.2711 - val_loss: 3.0512\n",
      "Epoch 153/300\n",
      "9928/9928 [==============================] - 2s - loss: 268.5868 - val_loss: 4.5491\n",
      "Epoch 154/300\n",
      "9928/9928 [==============================] - 2s - loss: 259.2548 - val_loss: 4.8390\n",
      "Epoch 155/300\n",
      "9928/9928 [==============================] - 2s - loss: 262.4526 - val_loss: 6.6111\n",
      "Epoch 156/300\n",
      "9928/9928 [==============================] - 2s - loss: 255.8838 - val_loss: 3.1825\n",
      "Epoch 157/300\n",
      "9928/9928 [==============================] - 2s - loss: 253.9456 - val_loss: 4.3623\n",
      "Epoch 158/300\n",
      "9928/9928 [==============================] - 2s - loss: 248.0563 - val_loss: 3.9355\n",
      "Epoch 159/300\n",
      "9928/9928 [==============================] - 2s - loss: 244.2486 - val_loss: 3.0048\n",
      "Epoch 160/300\n",
      "9928/9928 [==============================] - 3s - loss: 241.9859 - val_loss: 3.4201\n",
      "Epoch 161/300\n",
      "9928/9928 [==============================] - 2s - loss: 241.3016 - val_loss: 3.8483\n",
      "Epoch 162/300\n",
      "9928/9928 [==============================] - 2s - loss: 232.7949 - val_loss: 4.3342\n",
      "Epoch 163/300\n",
      "9928/9928 [==============================] - 2s - loss: 233.4674 - val_loss: 5.4293\n",
      "Epoch 164/300\n",
      "9928/9928 [==============================] - 2s - loss: 221.2763 - val_loss: 13.2147\n",
      "Epoch 165/300\n",
      "9928/9928 [==============================] - 2s - loss: 224.1158 - val_loss: 7.0660\n",
      "Epoch 166/300\n",
      "9928/9928 [==============================] - 2s - loss: 223.4915 - val_loss: 2.1594\n",
      "Epoch 167/300\n",
      "9928/9928 [==============================] - 2s - loss: 219.5782 - val_loss: 5.0713\n",
      "Epoch 168/300\n",
      "9928/9928 [==============================] - 2s - loss: 215.2075 - val_loss: 2.9118\n",
      "Epoch 169/300\n",
      "9928/9928 [==============================] - 3s - loss: 210.0899 - val_loss: 6.3094\n",
      "Epoch 170/300\n",
      "9928/9928 [==============================] - 2s - loss: 211.1534 - val_loss: 6.4787\n",
      "Epoch 171/300\n",
      "9928/9928 [==============================] - 2s - loss: 208.9828 - val_loss: 5.6071\n",
      "Epoch 172/300\n",
      "9928/9928 [==============================] - 2s - loss: 202.7514 - val_loss: 2.3785\n",
      "Epoch 173/300\n",
      "9928/9928 [==============================] - 2s - loss: 201.9795 - val_loss: 2.3628\n",
      "Epoch 174/300\n",
      "9928/9928 [==============================] - 3s - loss: 195.3780 - val_loss: 1.9321\n",
      "Epoch 175/300\n",
      "9928/9928 [==============================] - 2s - loss: 195.7117 - val_loss: 2.2270\n",
      "Epoch 176/300\n",
      "9928/9928 [==============================] - 2s - loss: 193.5081 - val_loss: 3.9203\n",
      "Epoch 177/300\n",
      "9928/9928 [==============================] - 2s - loss: 189.3271 - val_loss: 7.7542\n",
      "Epoch 178/300\n",
      "9928/9928 [==============================] - 3s - loss: 182.2156 - val_loss: 4.7438\n",
      "Epoch 179/300\n",
      "9928/9928 [==============================] - 2s - loss: 187.7249 - val_loss: 2.0846\n",
      "Epoch 180/300\n",
      "9928/9928 [==============================] - 2s - loss: 182.2506 - val_loss: 4.3527\n",
      "Epoch 181/300\n",
      "9928/9928 [==============================] - 2s - loss: 180.1705 - val_loss: 8.6669\n",
      "Epoch 182/300\n",
      "9928/9928 [==============================] - 2s - loss: 179.5535 - val_loss: 3.1302\n",
      "Epoch 183/300\n",
      "9928/9928 [==============================] - 2s - loss: 171.2064 - val_loss: 5.0423\n",
      "Epoch 184/300\n",
      "9928/9928 [==============================] - 2s - loss: 170.6993 - val_loss: 2.2896\n",
      "Epoch 185/300\n",
      "9928/9928 [==============================] - 2s - loss: 171.1771 - val_loss: 7.0204\n",
      "Epoch 186/300\n",
      "9928/9928 [==============================] - 2s - loss: 166.4393 - val_loss: 3.8010\n",
      "Epoch 187/300\n",
      "9928/9928 [==============================] - 2s - loss: 167.8759 - val_loss: 4.0293\n",
      "Epoch 188/300\n",
      "9928/9928 [==============================] - 2s - loss: 163.8577 - val_loss: 3.3051\n",
      "Epoch 189/300\n",
      "9928/9928 [==============================] - 3s - loss: 163.5316 - val_loss: 3.4163\n",
      "Epoch 190/300\n",
      "9928/9928 [==============================] - 3s - loss: 162.3587 - val_loss: 3.2814\n",
      "Epoch 191/300\n",
      "9928/9928 [==============================] - 2s - loss: 156.8501 - val_loss: 5.0774\n",
      "Epoch 192/300\n",
      "9928/9928 [==============================] - 2s - loss: 153.1802 - val_loss: 2.7866\n",
      "Epoch 193/300\n",
      "9928/9928 [==============================] - 2s - loss: 154.9681 - val_loss: 4.7738\n",
      "Epoch 194/300\n",
      "9928/9928 [==============================] - 2s - loss: 152.3726 - val_loss: 2.9072\n",
      "Epoch 195/300\n",
      "9928/9928 [==============================] - 2s - loss: 152.4478 - val_loss: 3.2633\n",
      "Epoch 196/300\n",
      "9928/9928 [==============================] - 2s - loss: 148.4564 - val_loss: 2.3637\n",
      "Epoch 197/300\n",
      "9928/9928 [==============================] - 2s - loss: 148.9209 - val_loss: 5.3164\n",
      "Epoch 198/300\n",
      "9928/9928 [==============================] - 3s - loss: 141.9037 - val_loss: 6.6442\n",
      "Epoch 199/300\n",
      "9928/9928 [==============================] - 2s - loss: 141.7246 - val_loss: 4.4515\n",
      "Epoch 200/300\n",
      "9928/9928 [==============================] - 3s - loss: 144.7672 - val_loss: 3.5129\n",
      "Epoch 201/300\n",
      "9928/9928 [==============================] - 2s - loss: 139.0000 - val_loss: 3.0070\n",
      "Epoch 202/300\n",
      "9928/9928 [==============================] - 3s - loss: 140.0177 - val_loss: 6.3497\n",
      "Epoch 203/300\n",
      "9928/9928 [==============================] - 3s - loss: 137.2578 - val_loss: 2.1735\n",
      "Epoch 204/300\n",
      "9928/9928 [==============================] - 2s - loss: 137.3415 - val_loss: 4.0843\n",
      "Epoch 205/300\n",
      "9928/9928 [==============================] - 2s - loss: 127.0981 - val_loss: 8.5902\n",
      "Epoch 206/300\n",
      "9928/9928 [==============================] - 2s - loss: 132.7942 - val_loss: 4.2522\n",
      "Epoch 207/300\n",
      "9928/9928 [==============================] - 2s - loss: 129.4463 - val_loss: 2.1399\n",
      "Epoch 208/300\n",
      "9928/9928 [==============================] - 2s - loss: 130.5057 - val_loss: 2.5578\n",
      "Epoch 209/300\n",
      "9928/9928 [==============================] - 3s - loss: 127.3785 - val_loss: 2.1420\n",
      "Epoch 210/300\n",
      "9928/9928 [==============================] - 3s - loss: 128.2115 - val_loss: 2.1401\n",
      "Epoch 211/300\n",
      "9928/9928 [==============================] - 3s - loss: 128.7062 - val_loss: 4.3800\n",
      "Epoch 212/300\n",
      "9928/9928 [==============================] - 2s - loss: 123.2316 - val_loss: 2.2020\n",
      "Epoch 213/300\n",
      "9928/9928 [==============================] - 2s - loss: 122.7428 - val_loss: 3.3615\n",
      "Epoch 214/300\n",
      "9928/9928 [==============================] - 3s - loss: 120.8736 - val_loss: 2.6590\n",
      "Epoch 215/300\n",
      "9928/9928 [==============================] - 2s - loss: 120.3510 - val_loss: 3.2017\n",
      "Epoch 216/300\n",
      "9928/9928 [==============================] - 2s - loss: 117.2829 - val_loss: 9.3709\n",
      "Epoch 217/300\n",
      "9928/9928 [==============================] - 2s - loss: 114.8745 - val_loss: 5.1768\n",
      "Epoch 218/300\n",
      "9928/9928 [==============================] - 3s - loss: 116.7851 - val_loss: 4.2887\n",
      "Epoch 219/300\n",
      "9928/9928 [==============================] - 2s - loss: 116.9583 - val_loss: 3.9736\n",
      "Epoch 220/300\n",
      "9928/9928 [==============================] - 3s - loss: 113.7756 - val_loss: 5.3315\n",
      "Epoch 221/300\n",
      "9928/9928 [==============================] - 3s - loss: 111.5384 - val_loss: 2.0354\n",
      "Epoch 222/300\n",
      "9928/9928 [==============================] - 2s - loss: 116.5623 - val_loss: 2.4730\n",
      "Epoch 223/300\n",
      "9928/9928 [==============================] - 2s - loss: 107.6616 - val_loss: 3.6192\n",
      "Epoch 224/300\n",
      "9928/9928 [==============================] - 3s - loss: 111.9917 - val_loss: 2.9311\n",
      "Epoch 225/300\n",
      "9928/9928 [==============================] - 3s - loss: 110.8205 - val_loss: 4.9418\n",
      "Epoch 226/300\n",
      "9928/9928 [==============================] - 2s - loss: 106.6703 - val_loss: 8.0575\n",
      "Epoch 227/300\n",
      "9928/9928 [==============================] - 2s - loss: 107.7291 - val_loss: 2.8894\n",
      "Epoch 228/300\n",
      "9928/9928 [==============================] - 3s - loss: 106.6410 - val_loss: 5.1862\n",
      "Epoch 229/300\n",
      "9928/9928 [==============================] - 2s - loss: 105.3852 - val_loss: 2.6047\n",
      "Epoch 230/300\n",
      "9928/9928 [==============================] - 3s - loss: 106.5438 - val_loss: 2.0744\n",
      "Epoch 231/300\n",
      "9928/9928 [==============================] - 2s - loss: 102.6774 - val_loss: 2.6618\n",
      "Epoch 232/300\n",
      "9928/9928 [==============================] - 2s - loss: 101.9618 - val_loss: 2.6137\n",
      "Epoch 233/300\n",
      "9928/9928 [==============================] - 2s - loss: 100.0221 - val_loss: 2.2743\n",
      "Epoch 234/300\n",
      "9928/9928 [==============================] - 3s - loss: 101.4608 - val_loss: 5.5790\n",
      "Epoch 235/300\n",
      "9928/9928 [==============================] - 3s - loss: 95.9677 - val_loss: 5.0842\n",
      "Epoch 236/300\n",
      "9928/9928 [==============================] - 3s - loss: 99.5242 - val_loss: 4.8882\n",
      "Epoch 237/300\n",
      "9928/9928 [==============================] - 2s - loss: 99.1991 - val_loss: 2.8509\n",
      "Epoch 238/300\n",
      "9928/9928 [==============================] - 3s - loss: 94.8559 - val_loss: 2.1417\n",
      "Epoch 239/300\n",
      "9928/9928 [==============================] - 3s - loss: 96.4277 - val_loss: 1.9799\n",
      "Epoch 240/300\n",
      "9928/9928 [==============================] - 3s - loss: 96.9281 - val_loss: 4.2181\n",
      "Epoch 241/300\n",
      "9928/9928 [==============================] - 3s - loss: 91.8986 - val_loss: 2.2976\n",
      "Epoch 242/300\n",
      "9928/9928 [==============================] - 3s - loss: 95.4826 - val_loss: 2.9066\n",
      "Epoch 243/300\n",
      "9928/9928 [==============================] - 2s - loss: 91.9873 - val_loss: 2.2918\n",
      "Epoch 244/300\n",
      "9928/9928 [==============================] - 3s - loss: 91.5164 - val_loss: 4.6804\n",
      "Epoch 245/300\n",
      "9928/9928 [==============================] - 2s - loss: 90.0325 - val_loss: 3.6640\n",
      "Epoch 246/300\n",
      "9928/9928 [==============================] - 3s - loss: 90.4555 - val_loss: 8.4458\n",
      "Epoch 247/300\n",
      "9928/9928 [==============================] - 2s - loss: 88.7897 - val_loss: 4.8164\n",
      "Epoch 248/300\n",
      "9928/9928 [==============================] - 3s - loss: 90.2818 - val_loss: 3.3787\n",
      "Epoch 249/300\n",
      "9928/9928 [==============================] - 4s - loss: 90.6452 - val_loss: 5.6999\n",
      "Epoch 250/300\n",
      "9928/9928 [==============================] - 4s - loss: 82.3294 - val_loss: 2.9106\n",
      "Epoch 251/300\n",
      "9928/9928 [==============================] - 4s - loss: 89.2750 - val_loss: 3.7018\n",
      "Epoch 252/300\n",
      "9928/9928 [==============================] - 4s - loss: 90.5124 - val_loss: 2.2290\n",
      "Epoch 253/300\n",
      "9928/9928 [==============================] - 4s - loss: 88.6361 - val_loss: 5.1428\n",
      "Epoch 254/300\n",
      "9928/9928 [==============================] - 4s - loss: 86.9181 - val_loss: 2.1210\n",
      "Epoch 255/300\n",
      "9928/9928 [==============================] - 4s - loss: 88.1088 - val_loss: 3.2035\n",
      "Epoch 256/300\n",
      "9928/9928 [==============================] - 4s - loss: 85.6374 - val_loss: 2.5173\n",
      "Epoch 257/300\n",
      "9928/9928 [==============================] - 4s - loss: 81.2829 - val_loss: 3.7782\n",
      "Epoch 258/300\n",
      "9928/9928 [==============================] - 4s - loss: 82.0208 - val_loss: 4.7397\n",
      "Epoch 259/300\n",
      "9928/9928 [==============================] - 4s - loss: 86.5218 - val_loss: 5.6636\n",
      "Epoch 260/300\n",
      "9928/9928 [==============================] - 4s - loss: 80.8906 - val_loss: 3.6282\n",
      "Epoch 261/300\n",
      "9928/9928 [==============================] - 4s - loss: 81.0111 - val_loss: 5.2536\n",
      "Epoch 262/300\n",
      "9928/9928 [==============================] - 4s - loss: 84.9640 - val_loss: 5.4312\n",
      "Epoch 263/300\n",
      "9928/9928 [==============================] - 4s - loss: 81.6948 - val_loss: 5.5652\n",
      "Epoch 264/300\n",
      "9928/9928 [==============================] - 4s - loss: 80.4946 - val_loss: 2.5577\n",
      "Epoch 265/300\n",
      "9928/9928 [==============================] - 4s - loss: 78.3581 - val_loss: 7.8871\n",
      "Epoch 266/300\n",
      "9928/9928 [==============================] - 4s - loss: 81.8818 - val_loss: 6.1692\n",
      "Epoch 267/300\n",
      "9928/9928 [==============================] - 4s - loss: 74.6946 - val_loss: 6.2453\n",
      "Epoch 268/300\n",
      "9928/9928 [==============================] - 4s - loss: 78.4333 - val_loss: 9.9908\n",
      "Epoch 269/300\n",
      "9928/9928 [==============================] - 4s - loss: 79.9411 - val_loss: 4.5135\n",
      "Epoch 270/300\n",
      "9928/9928 [==============================] - 4s - loss: 76.0573 - val_loss: 7.3531\n",
      "Epoch 271/300\n",
      "9928/9928 [==============================] - 4s - loss: 79.1654 - val_loss: 2.2868\n",
      "Epoch 272/300\n",
      "9928/9928 [==============================] - 4s - loss: 78.7617 - val_loss: 2.1473\n",
      "Epoch 273/300\n",
      "9928/9928 [==============================] - 4s - loss: 75.9858 - val_loss: 2.4844\n",
      "Epoch 274/300\n",
      "9928/9928 [==============================] - 4s - loss: 77.7526 - val_loss: 2.4193\n",
      "Epoch 275/300\n",
      "9928/9928 [==============================] - 4s - loss: 74.1389 - val_loss: 2.1538\n",
      "Epoch 276/300\n",
      "9928/9928 [==============================] - 4s - loss: 79.6334 - val_loss: 2.0475\n",
      "Epoch 277/300\n",
      "9928/9928 [==============================] - 4s - loss: 75.2883 - val_loss: 4.3269\n",
      "Epoch 278/300\n",
      "9928/9928 [==============================] - 4s - loss: 72.0653 - val_loss: 2.4937\n",
      "Epoch 279/300\n",
      "9928/9928 [==============================] - 4s - loss: 73.3253 - val_loss: 4.1298\n",
      "Epoch 280/300\n",
      "9928/9928 [==============================] - 4s - loss: 75.4272 - val_loss: 2.4369\n",
      "Epoch 281/300\n",
      "9928/9928 [==============================] - 4s - loss: 73.9558 - val_loss: 2.6119\n",
      "Epoch 282/300\n",
      "9928/9928 [==============================] - 4s - loss: 72.8219 - val_loss: 3.5732\n",
      "Epoch 283/300\n",
      "9928/9928 [==============================] - 4s - loss: 70.7490 - val_loss: 2.9046\n",
      "Epoch 284/300\n",
      "9928/9928 [==============================] - 4s - loss: 74.2995 - val_loss: 2.6539\n",
      "Epoch 285/300\n",
      "9928/9928 [==============================] - 5s - loss: 73.2511 - val_loss: 2.9054\n",
      "Epoch 286/300\n",
      "9928/9928 [==============================] - 4s - loss: 74.9078 - val_loss: 2.6635\n",
      "Epoch 287/300\n",
      "9928/9928 [==============================] - 4s - loss: 70.9690 - val_loss: 3.8864\n",
      "Epoch 288/300\n",
      "9928/9928 [==============================] - 3s - loss: 65.6740 - val_loss: 5.6720\n",
      "Epoch 289/300\n",
      "9928/9928 [==============================] - 3s - loss: 67.0629 - val_loss: 10.4939\n",
      "Epoch 290/300\n",
      "9928/9928 [==============================] - 3s - loss: 70.6143 - val_loss: 4.0644\n",
      "Epoch 291/300\n",
      "9928/9928 [==============================] - 3s - loss: 72.1523 - val_loss: 4.9578\n",
      "Epoch 292/300\n",
      "9928/9928 [==============================] - 3s - loss: 71.3949 - val_loss: 8.2330\n",
      "Epoch 293/300\n",
      "9928/9928 [==============================] - 3s - loss: 70.3947 - val_loss: 4.6998\n",
      "Epoch 294/300\n",
      "9928/9928 [==============================] - 3s - loss: 68.2821 - val_loss: 8.9478\n",
      "Epoch 295/300\n",
      "9928/9928 [==============================] - 3s - loss: 69.0167 - val_loss: 6.6526\n",
      "Epoch 296/300\n",
      "9928/9928 [==============================] - 3s - loss: 64.8462 - val_loss: 8.8355\n",
      "Epoch 297/300\n",
      "9928/9928 [==============================] - 3s - loss: 72.3401 - val_loss: 6.6935\n",
      "Epoch 298/300\n",
      "9928/9928 [==============================] - 3s - loss: 66.3474 - val_loss: 3.4620\n",
      "Epoch 299/300\n",
      "9928/9928 [==============================] - 3s - loss: 67.4153 - val_loss: 3.1231\n",
      "Epoch 300/300\n",
      "9928/9928 [==============================] - 3s - loss: 65.1090 - val_loss: 10.3438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x4c9c9a58>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=700, nb_epoch=500, validation_split=0.15,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 131.11024475]), [128.470001]),\n",
       " (array([ 132.18635559]), [124.94000200000001]),\n",
       " (array([ 128.33589172]), [125.860001]),\n",
       " (array([ 129.93501282]), [125.94000200000001]),\n",
       " (array([ 129.75747681]), [123.25]),\n",
       " (array([ 127.07476044]), [123.849998]),\n",
       " (array([ 128.11689758]), [126.150002]),\n",
       " (array([ 130.32107544]), [126.709999]),\n",
       " (array([ 130.48796082]), [125.099998]),\n",
       " (array([ 128.73202515]), [124.160004]),\n",
       " (array([ 128.11016846]), [125.019997]),\n",
       " (array([ 129.09962463]), [122.739998]),\n",
       " (array([ 126.69590759]), [123.459999]),\n",
       " (array([ 127.78218079]), [123.459999]),\n",
       " (array([ 127.57756042]), [124.58000200000001]),\n",
       " (array([ 128.7129364]), [121.129997]),\n",
       " (array([ 125.22927856]), [120.050003]),\n",
       " (array([ 124.77232361]), [118.529999]),\n",
       " (array([ 123.2224884]), [119.269997]),\n",
       " (array([ 123.92341614]), [119.099998]),\n",
       " (array([ 123.48387909]), [119.540001]),\n",
       " (array([ 123.96127319]), [121.5]),\n",
       " (array([ 125.93928528]), [123.879997]),\n",
       " (array([ 128.16056824]), [120.400002]),\n",
       " (array([ 124.45524597]), [123.18000000000001]),\n",
       " (array([ 127.89395905]), [122.120003]),\n",
       " (array([ 126.212677]), [121.540001]),\n",
       " (array([ 125.87197876]), [123.199997]),\n",
       " (array([ 127.59272766]), [125.94000200000001]),\n",
       " (array([ 130.17419434]), [126.519997]),\n",
       " (array([ 130.3059082]), [129.88999899999999]),\n",
       " (array([ 134.08958435]), [128.66000400000001]),\n",
       " (array([ 131.99926758]), [130.0]),\n",
       " (array([ 133.81480408]), [129.520004]),\n",
       " (array([ 132.92175293]), [130.0]),\n",
       " (array([ 133.58531189]), [128.529999]),\n",
       " (array([ 131.79498291]), [126.25]),\n",
       " (array([ 129.65322876]), [127.660004]),\n",
       " (array([ 131.55749512]), [128.86000100000001]),\n",
       " (array([ 132.61923218]), [127.980003]),\n",
       " (array([ 131.38645935]), [126.639999]),\n",
       " (array([ 130.13226318]), [127.55999799999999]),\n",
       " (array([ 131.3556366]), [128.86999499999999]),\n",
       " (array([ 132.63796997]), [129.16000400000001]),\n",
       " (array([ 132.71342468]), [129.050003]),\n",
       " (array([ 132.5349884]), [128.80999800000001]),\n",
       " (array([ 132.28170776]), [126.599998]),\n",
       " (array([ 129.93916321]), [125.220001]),\n",
       " (array([ 128.943573]), [125.800003]),\n",
       " (array([ 129.73674011]), [126.94000200000001]),\n",
       " (array([ 130.81910706]), [126.360001]),\n",
       " (array([ 129.98478699]), [124.589996]),\n",
       " (array([ 128.31509399]), [122.55999799999999]),\n",
       " (array([ 126.6725769]), [122.510002]),\n",
       " (array([ 126.87823486]), [122.989998]),\n",
       " (array([ 127.25134277]), [124.93000000000001]),\n",
       " (array([ 129.13929749]), [122.860001]),\n",
       " (array([ 126.75283813]), [122.5]),\n",
       " (array([ 126.81139374]), [123.379997]),\n",
       " (array([ 127.65667725]), [124.58000200000001]),\n",
       " (array([ 128.69987488]), [121.730003]),\n",
       " (array([ 125.75295258]), [118.410004]),\n",
       " (array([ 123.23647308]), [118.339996]),\n",
       " (array([ 123.2870636]), [115.0]),\n",
       " (array([ 119.76596069]), [114.33000200000001]),\n",
       " (array([ 119.14651489]), [117.290001]),\n",
       " (array([ 121.86164856]), [115.040001]),\n",
       " (array([ 118.90309143]), [118.040001]),\n",
       " (array([ 122.63868713]), [119.199997]),\n",
       " (array([ 123.34583282]), [118.970001]),\n",
       " (array([ 123.10276794]), [115.19000200000001]),\n",
       " (array([ 119.81193542]), [116.050003]),\n",
       " (array([ 120.92339325]), [111.470001]),\n",
       " (array([ 115.99200439]), [115.120003]),\n",
       " (array([ 119.93479919]), [118.849998]),\n",
       " (array([ 123.17622375]), [116.209999]),\n",
       " (array([ 119.77751923]), [115.360001]),\n",
       " (array([ 119.88993835]), [116.459999]),\n",
       " (array([ 120.93602753]), [120.110001]),\n",
       " (array([ 124.63510132]), [119.41999799999999]),\n",
       " (array([ 123.3447876]), [114.459999]),\n",
       " (array([ 119.20680237]), [116.959999]),\n",
       " (array([ 122.04571533]), [110.129997]),\n",
       " (array([ 114.77136993]), [104.739998]),\n",
       " (array([ 110.23736572]), [103.44000200000001]),\n",
       " (array([ 107.94696045]), [100.620003]),\n",
       " (array([ 103.80020142]), [95.650002000000001]),\n",
       " (array([ 98.64685822]), [90.550003000000004]),\n",
       " (array([ 93.63694763]), [89.0]),\n",
       " (array([ 91.39640808]), [87.75]),\n",
       " (array([ 89.74775696]), [92.209998999999996]),\n",
       " (array([ 95.4380722]), [93.599997999999999]),\n",
       " (array([ 95.79595947]), [88.290001000000004]),\n",
       " (array([ 89.74195099]), [91.519997000000004]),\n",
       " (array([ 94.85038757]), [90.779999000000004]),\n",
       " (array([ 92.45617676]), [92.510002]),\n",
       " (array([ 95.09806824]), [88.860000999999997]),\n",
       " (array([ 90.33330536]), [83.599997999999999]),\n",
       " (array([ 85.85141754]), [84.349997999999999]),\n",
       " (array([ 87.48744965]), [82.069999999999993]),\n",
       " (array([ 84.78573608]), [79.660004000000001]),\n",
       " (array([ 83.02507019]), [87.279999000000004]),\n",
       " (array([ 91.12893677]), [88.199996999999996]),\n",
       " (array([ 90.52572632]), [90.690002000000007]),\n",
       " (array([ 93.69630432]), [92.970000999999996]),\n",
       " (array([ 95.54875183]), [92.680000000000007]),\n",
       " (array([ 94.68243408]), [93.400002000000001]),\n",
       " (array([ 95.74613953]), [89.940002000000007]),\n",
       " (array([ 91.57382202]), [85.150002000000001]),\n",
       " (array([ 87.30300903]), [86.269997000000004]),\n",
       " (array([ 89.1942215]), [83.870002999999997]),\n",
       " (array([ 86.10388184]), [82.739998]),\n",
       " (array([ 85.65611267]), [79.739998]),\n",
       " (array([ 82.95445251]), [84.209998999999996]),\n",
       " (array([ 87.77029419]), [80.330002000000007]),\n",
       " (array([ 83.0249939]), [77.480002999999996]),\n",
       " (array([ 81.1917572]), [80.080002000000007]),\n",
       " (array([ 83.90775299]), [75.970000999999996]),\n",
       " (array([ 79.24511719]), [71.739998]),\n",
       " (array([ 75.53444672]), [74.879997000000003]),\n",
       " (array([ 78.62406921]), [79.889999000000003]),\n",
       " (array([ 82.5519104]), [80.650002000000001]),\n",
       " (array([ 83.44764709]), [81.669997999999993]),\n",
       " (array([ 84.69365692]), [81.599997999999999]),\n",
       " (array([ 84.57365417]), [76.900002000000001]),\n",
       " (array([ 80.35255432]), [79.839995999999999]),\n",
       " (array([ 83.7204895]), [80.669997999999993]),\n",
       " (array([ 83.65368652]), [77.440002000000007]),\n",
       " (array([ 80.70480347]), [80.589995999999999]),\n",
       " (array([ 84.17590332]), [84.860000999999997]),\n",
       " (array([ 87.73220825]), [82.690002000000007]),\n",
       " (array([ 85.39581299]), [82.860000999999997]),\n",
       " (array([ 85.88980865]), [80.580002000000007]),\n",
       " (array([ 83.59499359]), [82.199996999999996]),\n",
       " (array([ 85.5467453]), [82.769997000000004]),\n",
       " (array([ 85.661026]), [86.400002000000001]),\n",
       " (array([ 89.37954712]), [85.839995999999999]),\n",
       " (array([ 88.14474487]), [84.0]),\n",
       " (array([ 86.48693848]), [83.519997000000004]),\n",
       " (array([ 86.32622528]), [81.989998]),\n",
       " (array([ 84.87779236]), [80.599997999999999]),\n",
       " (array([ 83.84113312]), [80.519997000000004]),\n",
       " (array([ 83.89398193]), [81.330002000000007]),\n",
       " (array([ 84.52641296]), [81.25]),\n",
       " (array([ 84.30163574]), [83.550003000000004]),\n",
       " (array([ 86.60254669]), [84.160004000000001]),\n",
       " (array([ 86.85243225]), [87.370002999999997]),\n",
       " (array([ 90.27453613]), [86.819999999999993]),\n",
       " (array([ 88.99021912]), [89.230002999999996]),\n",
       " (array([ 91.99508667]), [87.790001000000004]),\n",
       " (array([ 89.6105423]), [87.180000000000007]),\n",
       " (array([ 89.44264221]), [84.699996999999996]),\n",
       " (array([ 86.85321045]), [85.709998999999996]),\n",
       " (array([ 88.51490784]), [85.339995999999999]),\n",
       " (array([ 87.72747803]), [83.190002000000007]),\n",
       " (array([ 85.74024963]), [84.120002999999997]),\n",
       " (array([ 87.10723114]), [84.919997999999993]),\n",
       " (array([ 87.60136414]), [81.980002999999996]),\n",
       " (array([ 84.63093567]), [91.419997999999993]),\n",
       " (array([ 95.82352448]), [90.069999999999993]),\n",
       " (array([ 91.79528046]), [89.489998]),\n",
       " (array([ 91.94617462]), [91.599997999999999]),\n",
       " (array([ 94.24775696]), [91.660004000000001]),\n",
       " (array([ 93.62403107]), [94.819999999999993]),\n",
       " (array([ 97.73075867]), [92.510002]),\n",
       " (array([ 94.01950073]), [91.650002000000001]),\n",
       " (array([ 93.92702484]), [90.930000000000007]),\n",
       " (array([ 93.06001282]), [93.480002999999996]),\n",
       " (array([ 96.18167114]), [92.830002000000007]),\n",
       " (array([ 94.60561371]), [92.410004000000001]),\n",
       " (array([ 94.56033325]), [96.139999000000003]),\n",
       " (array([ 99.14283752]), [96.819999999999993]),\n",
       " (array([ 98.67294312]), [93.269997000000004]),\n",
       " (array([ 94.95428467]), [95.160004000000001]),\n",
       " (array([ 98.0640564]), [95.069999999999993]),\n",
       " (array([ 96.94498444]), [93.839995999999999]),\n",
       " (array([ 95.75662231]), [90.669997999999993]),\n",
       " (array([ 92.663414]), [91.510002]),\n",
       " (array([ 94.11036682]), [88.930000000000007]),\n",
       " (array([ 90.52919769]), [88.790001000000004]),\n",
       " (array([ 91.09966278]), [84.370002999999997]),\n",
       " (array([ 86.24346924]), [86.400002000000001]),\n",
       " (array([ 89.4805603]), [85.900002000000001]),\n",
       " (array([ 88.11975861]), [88.970000999999996]),\n",
       " (array([ 91.86115265]), [92.029999000000004]),\n",
       " (array([ 94.748909]), [89.050003000000004]),\n",
       " (array([ 90.63659668]), [87.769997000000004]),\n",
       " (array([ 90.0213623]), [89.489998]),\n",
       " (array([ 92.08703613]), [87.480002999999996]),\n",
       " (array([ 89.21237183]), [85.809997999999993]),\n",
       " (array([ 88.04818726]), [83.480002999999996]),\n",
       " (array([ 85.95417023]), [87.25]),\n",
       " (array([ 90.48064423]), [88.620002999999997]),\n",
       " (array([ 90.93527222]), [90.400002000000001]),\n",
       " (array([ 93.01038361]), [90.360000999999997]),\n",
       " (array([ 92.41595459]), [91.220000999999996]),\n",
       " (array([ 93.54815674]), [92.910004000000001]),\n",
       " (array([ 95.34364319]), [91.949996999999996]),\n",
       " (array([ 93.78025818]), [92.660004000000001]),\n",
       " (array([ 95.03814697]), [92.510002]),\n",
       " (array([ 94.5533371]), [98.709998999999996]),\n",
       " (array([ 102.38729858]), [98.300003000000004]),\n",
       " (array([ 99.64233398]), [97.949996999999996]),\n",
       " (array([ 99.82854462]), [98.779999000000004]),\n",
       " (array([ 100.96144867]), [94.150002000000001]),\n",
       " (array([ 95.91925812]), [94.519997000000004]),\n",
       " (array([ 97.33668518]), [96.889999000000003]),\n",
       " (array([ 99.35401917]), [97.610000999999997]),\n",
       " (array([ 99.4307251]), [100.81999999999999]),\n",
       " (array([ 103.12289429]), [102.220001]),\n",
       " (array([ 103.7725296]), [101.55999799999999]),\n",
       " (array([ 103.07041931]), [98.75]),\n",
       " (array([ 100.85744476]), [101.19000200000001]),\n",
       " (array([ 104.01753235]), [101.699997]),\n",
       " (array([ 103.53547668]), [99.949996999999996]),\n",
       " (array([ 101.66014099]), [99.269997000000004]),\n",
       " (array([ 101.60342407]), [98.849997999999999]),\n",
       " (array([ 101.06745911]), [101.43000000000001]),\n",
       " (array([ 103.81233978]), [101.269997]),\n",
       " (array([ 102.8269043]), [100.43000000000001]),\n",
       " (array([ 102.28964996]), [102.30999799999999]),\n",
       " (array([ 104.73855591]), [102.550003]),\n",
       " (array([ 104.43403625]), [101.41999799999999]),\n",
       " (array([ 103.37752533]), [100.08000200000001]),\n",
       " (array([ 102.41598511]), [99.949996999999996]),\n",
       " (array([ 102.35948181]), [101.94000200000001]),\n",
       " (array([ 104.28939819]), [104.040001]),\n",
       " (array([ 106.05149841]), [103.209999]),\n",
       " (array([ 104.89177704]), [104.610001]),\n",
       " (array([ 107.18132019]), [106.19000200000001]),\n",
       " (array([ 108.80277252]), [105.849998]),\n",
       " (array([ 108.28260803]), [104.620003]),\n",
       " (array([ 107.41444397]), [102.589996]),\n",
       " (array([ 105.58226013]), [101.489998]),\n",
       " (array([ 104.41985321]), [102.900002]),\n",
       " (array([ 105.64569092]), [103.94000200000001]),\n",
       " (array([ 106.17376709]), [102.260002]),\n",
       " (array([ 104.25732422]), [101.050003]),\n",
       " (array([ 103.59539795]), [101.370003]),\n",
       " (array([ 103.9411087]), [104.58000200000001]),\n",
       " (array([ 107.21556091]), [105.510002]),\n",
       " (array([ 107.43123627]), [104.050003]),\n",
       " (array([ 106.18869019]), [102.81999999999999]),\n",
       " (array([ 105.62982941]), [101.889999]),\n",
       " (array([ 104.67289734]), [105.019997]),\n",
       " (array([ 108.00450134]), [102.93000000000001]),\n",
       " (array([ 104.8017807]), [104.69000200000001]),\n",
       " (array([ 107.51599121]), [106.279999]),\n",
       " (array([ 108.93730927]), [108.370003]),\n",
       " (array([ 111.15982819]), [106.83000200000001]),\n",
       " (array([ 109.43631744]), [106.489998]),\n",
       " (array([ 109.78089905]), [106.33000200000001]),\n",
       " (array([ 109.57185364]), [107.239998]),\n",
       " (array([ 110.41366577]), [107.489998]),\n",
       " (array([ 110.48962402]), [108.139999]),\n",
       " (array([ 111.28735352]), [108.349998]),\n",
       " (array([ 111.51369476]), [109.400002]),\n",
       " (array([ 112.74278259]), [108.209999]),\n",
       " (array([ 111.36720276]), [107.620003]),\n",
       " (array([ 111.08061218]), [107.31999999999999]),\n",
       " (array([ 110.7474823]), [107.0]),\n",
       " (array([ 110.27026367]), [106.33000200000001]),\n",
       " (array([ 109.51432037]), [105.889999]),\n",
       " (array([ 109.06652832]), [104.519997]),\n",
       " (array([ 107.55033875]), [104.44000200000001]),\n",
       " (array([ 107.5124054]), [104.150002]),\n",
       " (array([ 106.93597412]), [106.05999799999999]),\n",
       " (array([ 108.99319458]), [105.68000000000001]),\n",
       " (array([ 108.16654205]), [105.83000200000001]),\n",
       " (array([ 108.68048096]), [104.41999799999999]),\n",
       " (array([ 107.2700119]), [104.839996]),\n",
       " (array([ 107.89816284]), [101.730003]),\n",
       " (array([ 104.38679504]), [101.650002]),\n",
       " (array([ 104.62875366]), [100.19000200000001]),\n",
       " (array([ 102.59829712]), [100.68000000000001]),\n",
       " (array([ 103.08740234]), [102.08000200000001]),\n",
       " (array([ 104.28993225]), [100.83000200000001]),\n",
       " (array([ 102.56022644]), [103.620003]),\n",
       " (array([ 106.20194244]), [103.25]),\n",
       " (array([ 105.0817337]), [107.220001]),\n",
       " (array([ 110.15309143]), [110.639999]),\n",
       " (array([ 113.62169647]), [115.41999799999999]),\n",
       " (array([ 119.26018524]), [116.44000200000001]),\n",
       " (array([ 119.65979004]), [117.040001]),\n",
       " (array([ 120.8296814]), [115.56999999999999]),\n",
       " (array([ 119.70082092]), [117.05999799999999]),\n",
       " (array([ 121.52467346]), [117.639999]),\n",
       " (array([ 121.82165527]), [117.629997]),\n",
       " (array([ 121.81339264]), [117.279999]),\n",
       " (array([ 121.59144592]), [117.260002]),\n",
       " (array([ 121.64123535]), [117.860001]),\n",
       " (array([ 122.23085022]), [117.93000000000001]),\n",
       " (array([ 122.21206665]), [119.91999799999999]),\n",
       " (array([ 124.36701965]), [119.599998]),\n",
       " (array([ 123.77950287]), [118.470001]),\n",
       " (array([ 122.87410736]), [117.379997]),\n",
       " (array([ 121.97341156]), [119.33000200000001]),\n",
       " (array([ 123.95915222]), [118.699997]),\n",
       " (array([ 122.91149139]), [117.790001]),\n",
       " (array([ 122.21161652]), [119.290001]),\n",
       " (array([ 123.86312866]), [119.58000200000001]),\n",
       " (array([ 123.85896301]), [118.56999999999999]),\n",
       " (array([ 122.90421295]), [116.860001]),\n",
       " (array([ 121.45583344]), [117.629997]),\n",
       " (array([ 122.26980591]), [118.56999999999999]),\n",
       " (array([ 122.9332428]), [118.949997]),\n",
       " (array([ 123.20619202]), [119.900002]),\n",
       " (array([ 124.25747681]), [119.31999999999999]),\n",
       " (array([ 123.610672]), [118.83000200000001]),\n",
       " (array([ 123.29528046]), [119.470001]),\n",
       " (array([ 123.97633362]), [119.43000000000001]),\n",
       " (array([ 123.79177856]), [118.220001]),\n",
       " (array([ 122.63666534]), [118.050003]),\n",
       " (array([ 122.62039185]), [116.69000200000001]),\n",
       " (array([ 121.17937469]), [116.089996]),\n",
       " (array([ 120.63536835]), [116.33000200000001]),\n",
       " (array([ 120.74560547]), [117.459999]),\n",
       " (array([ 121.76180267]), [117.160004]),\n",
       " (array([ 121.29164886]), [116.760002]),\n",
       " (array([ 121.05966187]), [117.66999799999999]),\n",
       " (array([ 122.0729599]), [118.050003]),\n",
       " (array([ 122.3046875]), [118.879997]),\n",
       " (array([ 123.1987915]), [119.349998]),\n",
       " (array([ 123.65142059]), [121.81999999999999]),\n",
       " (array([ 126.27180481]), [121.879997]),\n",
       " (array([ 125.98667908]), [122.110001]),\n",
       " (array([ 126.36064148]), [121.56999999999999]),\n",
       " (array([ 125.84114075]), [121.610001]),\n",
       " (array([ 125.97413635]), [120.81999999999999]),\n",
       " (array([ 125.17456055]), [120.94000200000001]),\n",
       " (array([ 125.39043427]), [121.08000200000001]),\n",
       " (array([ 125.45918274]), [119.33000200000001]),\n",
       " (array([ 123.74221802]), [118.80999799999999]),\n",
       " (array([ 123.46022797]), [119.610001]),\n",
       " (array([ 124.15830994]), [117.900002]),\n",
       " (array([ 122.26524353]), [119.019997]),\n",
       " (array([ 123.64051819]), [119.75]),\n",
       " (array([ 124.10942841]), [121.349998]),\n",
       " (array([ 125.70600128]), [122.779999]),\n",
       " (array([ 127.01416779]), [122.290001]),\n",
       " (array([ 126.38465118]), [125.93000000000001]),\n",
       " (array([ 130.38825989]), [127.040001]),\n",
       " (array([ 130.8979187]), [127.019997]),\n",
       " (array([ 130.66278076]), [128.35000600000001]),\n",
       " (array([ 132.15510559]), [127.980003]),\n",
       " (array([ 131.48226929]), [121.639999]),\n",
       " (array([ 125.46528625]), [123.05999799999999]),\n",
       " (array([ 127.79164886]), [122.81999999999999]),\n",
       " (array([ 127.01144409]), [120.870003]),\n",
       " (array([ 125.15581512]), [122.69000200000001]),\n",
       " (array([ 127.22830963]), [120.360001]),\n",
       " (array([ 124.59286499]), [120.110001]),\n",
       " (array([ 124.73100281]), [120.650002]),\n",
       " (array([ 125.14186859]), [121.5]),\n",
       " (array([ 125.85087585]), [122.870003]),\n",
       " (array([ 127.14735413]), [120.610001]),\n",
       " (array([ 124.78455353]), [120.55999799999999]),\n",
       " (array([ 125.15101624]), [121.160004]),\n",
       " (array([ 125.60570526]), [121.290001]),\n",
       " (array([ 125.59751892]), [123.099998]),\n",
       " (array([ 127.45664978]), [123.489998]),\n",
       " (array([ 127.5657196]), [126.0]),\n",
       " (array([ 130.21051025]), [126.910004]),\n",
       " (array([ 130.73257446]), [127.19000200000001]),\n",
       " (array([ 130.87342834]), [126.260002]),\n",
       " (array([ 129.84643555]), [127.029999]),\n",
       " (array([ 130.84625244]), [128.21000700000002]),\n",
       " (array([ 131.9884491]), [128.63000500000001]),\n",
       " (array([ 132.23402405]), [128.14999399999999]),\n",
       " (array([ 131.61561584]), [127.540001]),\n",
       " (array([ 131.04452515]), [126.959999]),\n",
       " (array([ 130.53126526]), [128.199997]),\n",
       " (array([ 131.99604797]), [127.93000000000001]),\n",
       " (array([ 131.45600891]), [127.279999]),\n",
       " (array([ 130.80209351]), [125.699997]),\n",
       " (array([ 129.27536011]), [126.349998]),\n",
       " (array([ 130.23135376]), [127.94000200000001]),\n",
       " (array([ 131.82183838]), [127.209999]),\n",
       " (array([ 130.71485901]), [127.550003]),\n",
       " (array([ 131.23774719]), [127.25]),\n",
       " (array([ 130.8323822]), [127.040001]),\n",
       " (array([ 130.6663208]), [126.800003]),\n",
       " (array([ 130.44534302]), [128.38999899999999]),\n",
       " (array([ 132.24131775]), [129.33999599999999]),\n",
       " (array([ 133.02038574]), [129.679993]),\n",
       " (array([ 133.22518921]), [129.929993]),\n",
       " (array([ 133.45370483]), [128.490005]),\n",
       " (array([ 131.76161194]), [128.71000700000002]),\n",
       " (array([ 132.29776001]), [127.400002]),\n",
       " (array([ 130.79246521]), [127.910004]),\n",
       " (array([ 131.60258484]), [128.64999399999999]),\n",
       " (array([ 132.31529236]), [129.929993]),\n",
       " (array([ 133.65686035]), [130.0]),\n",
       " (array([ 133.48596191]), [130.570007]),\n",
       " (array([ 134.15768433]), [132.30999800000001]),\n",
       " (array([ 136.18283081]), [131.85000600000001]),\n",
       " (array([ 135.27742004]), [132.570007]),\n",
       " (array([ 136.25759888]), [130.89999399999999]),\n",
       " (array([ 134.06523132]), [132.449997]),\n",
       " (array([ 136.31665039]), [130.85000600000001]),\n",
       " (array([ 134.05751038]), [130.0]),\n",
       " (array([ 133.34552002]), [129.550003]),\n",
       " (array([ 132.95115662]), [130.85000600000001]),\n",
       " (array([ 134.58036804]), [129.479996]),\n",
       " (array([ 132.72372437]), [130.509995]),\n",
       " (array([ 134.22381592]), [130.229996]),\n",
       " (array([ 133.65510559]), [132.30999800000001]),\n",
       " (array([ 136.26799011]), [131.779999]),\n",
       " (array([ 135.20666504]), [134.13999899999999]),\n",
       " (array([ 138.30166626]), [130.25]),\n",
       " (array([ 133.14317322]), [129.0]),\n",
       " (array([ 132.41575623]), [125.5]),\n",
       " (array([ 128.83824158]), [126.120003]),\n",
       " (array([ 130.08328247]), [125.75]),\n",
       " (array([ 129.52107239]), [126.33000200000001]),\n",
       " (array([ 130.17674255]), [123.75]),\n",
       " (array([ 127.493927]), [122.389999]),\n",
       " (array([ 126.6468277]), [124.66999799999999]),\n",
       " (array([ 129.0405426]), [125.529999]),\n",
       " (array([ 129.4822998]), [125.660004]),\n",
       " (array([ 129.4803772]), [123.0]),\n",
       " (array([ 126.87184906]), [123.519997]),\n",
       " (array([ 127.82518768]), [121.879997]),\n",
       " (array([ 126.06725311]), [123.209999]),\n",
       " (array([ 127.60926819]), [122.80999799999999]),\n",
       " (array([ 126.92602539]), [123.730003]),\n",
       " (array([ 127.94313049]), [124.0]),\n",
       " (array([ 128.05451965]), [125.230003]),\n",
       " (array([ 129.29808044]), [126.33000200000001]),\n",
       " (array([ 130.24568176]), [127.80999799999999]),\n",
       " (array([ 131.67205811]), [127.19000200000001]),\n",
       " (array([ 130.71331787]), [126.849998]),\n",
       " (array([ 130.4823761]), [126.459999]),\n",
       " (array([ 130.12207031]), [127.589996]),\n",
       " (array([ 131.40968323]), [127.06999999999999]),\n",
       " (array([ 130.62850952]), [127.160004]),\n",
       " (array([ 130.83372498]), [128.570007]),\n",
       " (array([ 132.37121582]), [127.41999799999999]),\n",
       " (array([ 130.83531189]), [126.879997]),\n",
       " (array([ 130.48820496]), [126.720001]),\n",
       " (array([ 130.39419556]), [127.25]),\n",
       " (array([ 130.98516846]), [126.410004]),\n",
       " (array([ 129.99185181]), [125.550003]),\n",
       " (array([ 129.26875305]), [125.620003]),\n",
       " (array([ 129.47990417]), [127.599998]),\n",
       " (array([ 131.5841217]), [127.94000200000001]),\n",
       " (array([ 131.58071899]), [127.83000200000001]),\n",
       " (array([ 131.39398193]), [128.66999799999999]),\n",
       " (array([ 132.35519409]), [127.760002]),\n",
       " (array([ 131.18270874]), [128.38000500000001]),\n",
       " (array([ 132.05601501]), [127.709999]),\n",
       " (array([ 131.18251038]), [127.980003]),\n",
       " (array([ 131.60998535]), [129.36999499999999]),\n",
       " (array([ 133.13078308]), [128.529999]),\n",
       " (array([ 131.90708923]), [129.240005]),\n",
       " (array([ 132.89802551]), [129.259995]),\n",
       " (array([ 132.7538147]), [128.58999599999999]),\n",
       " (array([ 131.99639893]), [128.770004]),\n",
       " (array([ 132.32876587]), [128.25]),\n",
       " (array([ 131.70074463]), [128.25]),\n",
       " (array([ 131.80555725]), [129.35000600000001]),\n",
       " (array([ 133.05148315]), [128.929993]),\n",
       " (array([ 132.35798645]), [128.479996]),\n",
       " (array([ 131.94325256]), [127.610001]),\n",
       " (array([ 131.05944824]), [128.759995]),\n",
       " (array([ 132.50460815]), [128.36000100000001]),\n",
       " (array([ 131.83174133]), [129.029999]),\n",
       " (array([ 132.67399597]), [131.25]),\n",
       " (array([ 135.17910767]), [130.88999899999999]),\n",
       " (array([ 134.31570435]), [130.63000500000001]),\n",
       " (array([ 134.06900024]), [132.229996]),\n",
       " (array([ 136.06645203]), [129.69000199999999]),\n",
       " (array([ 132.73538208]), [128.990005]),\n",
       " (array([ 132.43710327]), [129.13000500000001]),\n",
       " (array([ 132.65835571]), [129.990005]),\n",
       " (array([ 133.62774658]), [130.729996]),\n",
       " (array([ 134.34472656]), [128.820007]),\n",
       " (array([ 131.99060059]), [130.10000600000001]),\n",
       " (array([ 133.87353516]), [130.46000700000002]),\n",
       " (array([ 134.00906372]), [129.0]),\n",
       " (array([ 132.24035645]), [129.60000600000001]),\n",
       " (array([ 133.22570801]), [128.11999499999999]),\n",
       " (array([ 131.41706848]), [127.459999]),\n",
       " (array([ 130.989151]), [123.91999799999999]),\n",
       " (array([ 127.54053497]), [122.099998]),\n",
       " (array([ 126.42166138]), [126.269997]),\n",
       " (array([ 130.84170532]), [126.889999]),\n",
       " (array([ 130.69506836]), [132.679993]),\n",
       " (array([ 137.62081909]), [131.479996]),\n",
       " (array([ 134.96305847]), [131.19000199999999]),\n",
       " (array([ 134.71606445]), [130.44000199999999]),\n",
       " (array([ 133.76545715]), [129.949997]),\n",
       " (array([ 133.3324585]), [128.86000100000001]),\n",
       " (array([ 132.17352295]), [123.800003]),\n",
       " (array([ 127.25073242]), [125.41999799999999]),\n",
       " (array([ 129.72894287]), [124.449997]),\n",
       " (array([ 128.32423401]), [124.519997]),\n",
       " (array([ 128.53768921]), [123.230003]),\n",
       " (array([ 127.24028778]), [126.389999]),\n",
       " (array([ 130.73699951]), [125.260002]),\n",
       " (array([ 128.94670105]), [124.339996]),\n",
       " (array([ 128.24691772]), [127.410004]),\n",
       " (array([ 131.64375305]), [127.959999]),\n",
       " (array([ 131.66177368]), [125.279999]),\n",
       " (array([ 128.72712708]), [124.129997]),\n",
       " (array([ 128.09924316]), [123.720001]),\n",
       " (array([ 127.81961823]), [123.900002]),\n",
       " (array([ 128.01385498]), [127.68000000000001]),\n",
       " (array([ 132.03407288]), [128.449997]),\n",
       " (array([ 132.16972351]), [128.5]),\n",
       " (array([ 132.04936218]), [129.78999299999998]),\n",
       " (array([ 133.5231781]), [130.35000600000001]),\n",
       " (array([ 133.92837524]), [130.979996]),\n",
       " (array([ 134.58125305]), [130.14999399999999]),\n",
       " (array([ 133.46626282]), [130.64999399999999]),\n",
       " (array([ 134.22912598]), [129.300003]),\n",
       " (array([ 132.54660034]), [130.11000100000001]),\n",
       " (array([ 133.76701355]), [128.19000199999999]),\n",
       " (array([ 131.4099884]), [127.120003]),\n",
       " (array([ 130.62945557]), [128.979996]),\n",
       " (array([ 132.8575592]), [125.089996]),\n",
       " (array([ 128.42146301]), [123.480003]),\n",
       " (array([ 127.58839417]), [122.56999999999999]),\n",
       " (array([ 126.83032227]), [121.860001]),\n",
       " (array([ 126.1932373]), [123.459999]),\n",
       " (array([ 127.82530212]), [127.0]),\n",
       " (array([ 131.32510376]), [127.970001]),\n",
       " (array([ 131.73127747]), [127.959999]),\n",
       " (array([ 131.52998352]), [128.66999799999999]),\n",
       " (array([ 132.3309021]), [130.479996]),\n",
       " (array([ 134.31274414]), [130.720001]),\n",
       " (array([ 134.24577332]), [130.720001]),\n",
       " (array([ 134.19921875]), [128.029999]),\n",
       " (array([ 131.12680054]), [129.78999299999998]),\n",
       " (array([ 133.67948914]), [126.550003]),\n",
       " (array([ 129.7673645]), [125.269997]),\n",
       " (array([ 129.07054138]), [127.470001]),\n",
       " (array([ 131.52119446]), [128.38000500000001]),\n",
       " (array([ 132.11383057]), [128.41000400000001]),\n",
       " (array([ 131.95379639]), [128.63000500000001]),\n",
       " (array([ 132.19694519]), [128.429993]),\n",
       " (array([ 131.92623901]), [128.020004]),\n",
       " (array([ 131.51318359]), [128.39999399999999]),\n",
       " (array([ 132.01164246]), [130.759995]),\n",
       " (array([ 134.71150208]), [130.36999499999999]),\n",
       " (array([ 133.78770447]), [131.270004]),\n",
       " (array([ 134.95419312]), [131.83000200000001]),\n",
       " (array([ 135.44026184]), [130.13999899999999]),\n",
       " (array([ 133.30097961]), [132.0]),\n",
       " (array([ 135.91346741]), [131.83999599999999]),\n",
       " (array([ 135.34329224]), [129.83000200000001]),\n",
       " (array([ 132.94476318]), [128.300003]),\n",
       " (array([ 131.5960083]), [127.870003]),\n",
       " (array([ 131.39002991]), [127.769997]),\n",
       " (array([ 131.34336853]), [128.449997]),\n",
       " (array([ 132.11515808]), [129.38999899999999]),\n",
       " (array([ 133.05984497]), [128.89999399999999]),\n",
       " (array([ 132.31462097]), [127.5]),\n",
       " (array([ 130.8757782]), [126.470001]),\n",
       " (array([ 130.03974915]), [124.900002]),\n",
       " (array([ 128.61961365]), [125.269997]),\n",
       " (array([ 129.24674988]), [122.779999]),\n",
       " (array([ 126.73330688]), [124.730003]),\n",
       " (array([ 129.07798767]), [123.400002]),\n",
       " (array([ 127.33943176]), [123.129997]),\n",
       " (array([ 127.3168335]), [125.769997]),\n",
       " (array([ 130.04949951]), [125.040001]),\n",
       " (array([ 128.79611206]), [127.58000200000001]),\n",
       " (array([ 131.70431519]), [125.949997]),\n",
       " (array([ 129.47293091]), [126.08000200000001]),\n",
       " (array([ 129.9259491]), [126.360001]),\n",
       " (array([ 130.15080261]), [127.989998]),\n",
       " (array([ 131.87216187]), [129.61000100000001]),\n",
       " (array([ 133.41835022]), [128.85000600000001]),\n",
       " (array([ 132.21942139]), [129.429993]),\n",
       " (array([ 133.05718994]), [129.66999799999999]),\n",
       " (array([ 133.1925354]), [130.19000199999999]),\n",
       " (array([ 133.76165771]), [131.78999299999998]),\n",
       " (array([ 135.60847473]), [131.979996]),\n",
       " (array([ 135.53379822]), [132.570007]),\n",
       " (array([ 136.22407532]), [131.66999799999999]),\n",
       " (array([ 134.98797607]), [134.11000100000001]),\n",
       " (array([ 138.26956177]), [134.64999399999999]),\n",
       " (array([ 138.50300598]), [134.88999899999999]),\n",
       " (array([ 138.63424683]), [135.479996]),\n",
       " (array([ 139.32627869]), [134.13999899999999]),\n",
       " (array([ 137.50881958]), [135.63999899999999]),\n",
       " (array([ 139.69543457]), [135.25]),\n",
       " (array([ 138.92456055]), [137.66000400000001]),\n",
       " (array([ 142.10009766]), [137.83999599999999]),\n",
       " (array([ 141.89627075]), [138.720001]),\n",
       " (array([ 142.89173889]), [138.85000600000001]),\n",
       " (array([ 142.87417603]), [139.66000400000001]),\n",
       " (array([ 143.83096313]), [139.85000600000001]),\n",
       " (array([ 143.90350342]), [140.36999499999999]),\n",
       " (array([ 144.46894836]), [141.5]),\n",
       " (array([ 145.70620728]), [141.05999800000001]),\n",
       " (array([ 145.00733948]), [142.83000200000001]),\n",
       " (array([ 147.09472656]), [138.029999]),\n",
       " (array([ 141.4152832]), [139.070007]),\n",
       " (array([ 143.42869568]), [139.83000200000001]),\n",
       " (array([ 144.05284119]), [139.66999799999999]),\n",
       " (array([ 143.65606689]), [139.83999599999999]),\n",
       " (array([ 143.86123657]), [140.66999799999999]),\n",
       " (array([ 144.82278442]), [141.429993]),\n",
       " (array([ 145.56762695]), [140.89999399999999]),\n",
       " (array([ 144.82510376]), [143.60000600000001]),\n",
       " (array([ 148.0319519]), [143.320007]),\n",
       " (array([ 147.27490234]), [143.83999599999999]),\n",
       " (array([ 147.79605103]), [144.16999799999999]),\n",
       " (array([ 148.02880859]), [146.78999299999998]),\n",
       " (array([ 150.88079834]), [146.91999799999999]),\n",
       " (array([ 150.56652832]), [146.46000700000002]),\n",
       " (array([ 150.00509644]), [146.13999899999999]),\n",
       " (array([ 149.69166565]), [146.550003]),\n",
       " (array([ 150.17233276]), [145.429993]),\n",
       " (array([ 148.92349243]), [143.740005]),\n",
       " (array([ 147.30641174]), [143.63999899999999]),\n",
       " (array([ 147.43218994]), [142.240005]),\n",
       " (array([ 145.93023682]), [141.949997]),\n",
       " (array([ 145.83091736]), [144.36000100000001]),\n",
       " (array([ 148.62203979]), [145.050003]),\n",
       " (array([ 148.99217224]), [145.38999899999999]),\n",
       " (array([ 149.1776123]), [143.179993]),\n",
       " (array([ 146.72714233]), [145.80999800000001]),\n",
       " (array([ 150.01173401]), [143.89999399999999]),\n",
       " (array([ 147.54629517]), [142.88999899999999]),\n",
       " (array([ 146.69483948]), [141.46000700000002]),\n",
       " (array([ 145.1630249]), [144.41000400000001]),\n",
       " (array([ 148.79222107]), [145.179993]),\n",
       " (array([ 149.17947388]), [145.38000500000001]),\n",
       " (array([ 149.15527344]), [144.990005]),\n",
       " (array([ 148.65921021]), [144.020004]),\n",
       " (array([ 147.6678009]), [144.979996]),\n",
       " (array([ 148.85134888]), [144.300003]),\n",
       " (array([ 147.98959351]), [144.820007]),\n",
       " (array([ 148.65527344]), [144.279999]),\n",
       " (array([ 147.97940063]), [145.820007]),\n",
       " (array([ 149.73722839]), [144.720001]),\n",
       " (array([ 148.33052063]), [144.550003]),\n",
       " (array([ 148.31098938]), [145.0]),\n",
       " (array([ 148.77632141]), [144.509995]),\n",
       " (array([ 148.19949341]), [145.740005]),\n",
       " (array([ 149.60472107]), [145.949997]),\n",
       " (array([ 149.63867188]), [145.88999899999999]),\n",
       " (array([ 149.53192139]), [145.33999599999999]),\n",
       " (array([ 148.93621826]), [145.71000700000002]),\n",
       " (array([ 149.41639709]), [146.520004]),\n",
       " (array([ 150.22470093]), [146.66999799999999]),\n",
       " (array([ 150.26350403]), [146.759995]),\n",
       " (array([ 150.32989502]), [147.479996]),\n",
       " (array([ 151.07272339]), [147.63999899999999]),\n",
       " (array([ 151.12409973]), [147.050003]),\n",
       " (array([ 150.47267151]), [148.66000400000001]),\n",
       " (array([ 152.29399109]), [147.929993]),\n",
       " (array([ 151.24740601]), [147.63999899999999]),\n",
       " (array([ 151.07780457]), [147.279999]),\n",
       " (array([ 150.69142151]), [149.10000600000001]),\n",
       " (array([ 152.71714783]), [148.820007]),\n",
       " (array([ 152.12507629]), [150.0]),\n",
       " (array([ 153.45661926]), [150.64999399999999]),\n",
       " (array([ 153.90937805]), [155.69000199999999]),\n",
       " (array([ 159.49246216]), [155.800003]),\n",
       " (array([ 158.69895935]), [155.5]),\n",
       " (array([ 158.38450623]), [159.63000500000001]),\n",
       " (array([ 162.99383545]), [161.44000199999999]),\n",
       " (array([ 164.23742676]), [161.03999299999998]),\n",
       " (array([ 163.56599426]), [161.070007]),\n",
       " (array([ 163.72619629]), [159.21000700000002]),\n",
       " (array([ 161.66485596]), [162.0]),\n",
       " (array([ 165.09432983]), [163.55999800000001]),\n",
       " (array([ 166.16551208]), [163.300003]),\n",
       " (array([ 165.67025757]), [163.529999]),\n",
       " (array([ 165.99645996]), [164.0]),\n",
       " (array([ 166.41319275]), [164.820007]),\n",
       " (array([ 167.19909668]), [166.050003]),\n",
       " (array([ 168.3578949]), [164.64999399999999]),\n",
       " (array([ 166.67878723]), [164.08999599999999]),\n",
       " (array([ 166.40571594]), [163.85000600000001]),\n",
       " (array([ 166.1803894]), [163.220001]),\n",
       " (array([ 165.55908203]), [162.83999599999999]),\n",
       " (array([ 165.27467346]), [163.39999399999999]),\n",
       " (array([ 165.90643311]), [164.240005]),\n",
       " (array([ 166.67510986]), [164.83999599999999]),\n",
       " (array([ 167.17224121]), [161.949997]),\n",
       " (array([ 164.06829834]), [160.179993]),\n",
       " (array([ 162.78187561]), [160.770004]),\n",
       " (array([ 163.54370117]), [162.279999]),\n",
       " (array([ 164.98529053]), [161.88000500000001]),\n",
       " (array([ 164.33651733]), [159.970001]),\n",
       " (array([ 162.42202759]), [160.16000400000001]),\n",
       " (array([ 162.95259094]), [163.479996]),\n",
       " (array([ 166.43807983]), [161.83000200000001]),\n",
       " (array([ 164.11152649]), [159.929993]),\n",
       " (array([ 162.49090576]), [162.279999]),\n",
       " (array([ 165.24719238]), [165.86000100000001]),\n",
       " (array([ 168.63600159]), [162.020004]),\n",
       " (array([ 163.9826355]), [162.429993]),\n",
       " (array([ 165.31156921]), [161.38999899999999]),\n",
       " (array([ 163.7976532]), [159.020004]),\n",
       " (array([ 161.47984314]), [153.0]),\n",
       " (array([ 155.26525879]), [154.179993]),\n",
       " (array([ 157.7106781]), [155.88999899999999]),\n",
       " (array([ 158.88865662]), [157.679993]),\n",
       " (array([ 160.6479187]), [158.0]),\n",
       " (array([ 160.74479675]), [159.529999]),\n",
       " (array([ 162.43328857]), [160.03999299999998]),\n",
       " (array([ 162.72094727]), [162.179993]),\n",
       " (array([ 165.03829956]), [161.36999499999999]),\n",
       " (array([ 163.7943573]), [162.88000500000001]),\n",
       " (array([ 165.65612793]), [163.60000600000001]),\n",
       " (array([ 166.06690979]), [163.070007]),\n",
       " (array([ 165.43440247]), [164.270004]),\n",
       " (array([ 166.82058716]), [164.25]),\n",
       " (array([ 166.53916931]), [163.990005]),\n",
       " (array([ 166.31370544]), [164.03999299999998]),\n",
       " (array([ 166.3989563]), [164.38000500000001]),\n",
       " (array([ 166.73254395]), [164.050003]),\n",
       " (array([ 166.33265686]), [163.949997]),\n",
       " (array([ 166.30282593]), [163.25]),\n",
       " (array([ 165.57351685]), [163.949997]),\n",
       " (array([ 166.4369812]), [164.970001]),\n",
       " (array([ 167.35400391]), [166.21000700000002]),\n",
       " (array([ 168.50024414]), [165.94000199999999]),\n",
       " (array([ 167.97140503]), [165.39999399999999]),\n",
       " (array([ 167.49243164]), [164.75]),\n",
       " (array([ 166.90643311]), [168.279999]),\n",
       " (array([ 170.76068115]), [167.66999799999999]),\n",
       " (array([ 169.4074707]), [168.490005]),\n",
       " (array([ 170.40704346]), [170.36999499999999]),\n",
       " (array([ 172.09002686]), [170.779999]),\n",
       " (array([ 172.11927795]), [170.58000200000001]),\n",
       " (array([ 171.80732727]), [172.14999399999999]),\n",
       " (array([ 173.44743347]), [172.86999499999999]),\n",
       " (array([ 173.83456421]), [170.61999499999999]),\n",
       " (array([ 171.36172485]), [168.46000700000002]),\n",
       " (array([ 169.71807861]), [168.88999899999999]),\n",
       " (array([ 170.55671692]), [169.10000600000001]),\n",
       " (array([ 170.65730286]), [170.38000500000001]),\n",
       " (array([ 171.97203064]), [169.5]),\n",
       " (array([ 170.77357483]), [172.240005]),\n",
       " (array([ 173.83900452]), [169.91999799999999]),\n",
       " (array([ 170.84902954]), [168.86000100000001]),\n",
       " (array([ 170.31820679]), [170.5]),\n",
       " (array([ 172.10946655]), [170.44000199999999]),\n",
       " (array([ 171.71061707]), [170.58999599999999]),\n",
       " (array([ 171.89401245]), [170.16000400000001]),\n",
       " (array([ 171.38140869]), [168.259995]),\n",
       " (array([ 169.56314087]), [167.990005]),\n",
       " (array([ 169.69450378]), [167.75]),\n",
       " (array([ 169.45727539]), [167.179993]),\n",
       " (array([ 168.94444275]), [167.5]),\n",
       " (array([ 169.40213013]), [168.929993]),\n",
       " (array([ 170.81378174]), [166.55999800000001]),\n",
       " (array([ 168.11938477]), [166.08999599999999]),\n",
       " (array([ 168.15931702]), [165.050003]),\n",
       " (array([ 167.07684326]), [164.75]),\n",
       " (array([ 166.97750854]), [163.69000199999999]),\n",
       " (array([ 165.90544128]), [164.33999599999999]),\n",
       " (array([ 166.78283691]), [164.83999599999999]),\n",
       " (array([ 167.14266968]), [163.179993]),\n",
       " (array([ 165.35845947]), [163.16999799999999]),\n",
       " (array([ 165.68612671]), [164.11999499999999]),\n",
       " (array([ 166.59025574]), [162.33000200000001]),\n",
       " (array([ 164.56005859]), [162.66999799999999]),\n",
       " (array([ 165.30841064]), [164.44000199999999]),\n",
       " (array([ 167.02127075]), [165.020004]),\n",
       " (array([ 167.31771851]), [166.220001]),\n",
       " (array([ 168.52230835]), [165.679993]),\n",
       " (array([ 167.7016449]), [166.11999499999999]),\n",
       " (array([ 168.29568481]), [165.070007]),\n",
       " (array([ 167.09234619]), [167.61999499999999]),\n",
       " (array([ 170.01828003]), [170.009995]),\n",
       " (array([ 171.95866394]), [170.53999299999998]),\n",
       " (array([ 171.98654175]), [171.550003]),\n",
       " (array([ 172.87597656]), [174.53999299999998]),\n",
       " (array([ 175.73774719]), [175.429993]),\n",
       " (array([ 176.01464844]), [177.71000700000002]),\n",
       " (array([ 178.199646]), [176.479996]),\n",
       " (array([ 176.32611084]), [176.490005]),\n",
       " (array([ 176.61807251]), [174.990005]),\n",
       " (array([ 174.94673157]), [174.050003]),\n",
       " (array([ 174.35058594]), [174.320007]),\n",
       " (array([ 174.81564331]), [174.229996]),\n",
       " (array([ 174.67602539]), [175.53999299999998]),\n",
       " (array([ 176.09346008]), [175.279999]),\n",
       " (array([ 175.51902771]), [185.21000700000002]),\n",
       " (array([ 187.15124512]), [183.64999399999999]),\n",
       " (array([ 183.8346405]), [184.89999399999999]),\n",
       " (array([ 184.88183594]), [185.179993]),\n",
       " (array([ 184.65567017]), [183.699997]),\n",
       " (array([ 182.88217163]), [182.929993]),\n",
       " (array([ 182.27163696]), [181.35000600000001]),\n",
       " (array([ 180.54930115]), [181.800003]),\n",
       " (array([ 181.40809631]), [181.85000600000001]),\n",
       " (array([ 181.32778931]), [180.75]),\n",
       " (array([ 180.08569336]), [178.050003]),\n",
       " (array([ 177.32304382]), [178.83000200000001]),\n",
       " (array([ 178.78051758]), [171.479996]),\n",
       " (array([ 171.02151489]), [172.979996]),\n",
       " (array([ 174.4584198]), [166.220001]),\n",
       " (array([ 167.03132629]), [170.61000100000001]),\n",
       " (array([ 173.28488159]), [162.53999299999998]),\n",
       " (array([ 163.91444397]), [166.729996]),\n",
       " (array([ 170.31829834]), [168.199997]),\n",
       " (array([ 170.3497467]), [172.990005]),\n",
       " (array([ 175.03456116]), [171.240005]),\n",
       " (array([ 172.15315247]), [171.479996]),\n",
       " (array([ 172.73730469]), [163.83000200000001]),\n",
       " (array([ 164.9223175]), [157.53999299999998]),\n",
       " (array([ 160.09977722]), [158.979996]),\n",
       " (array([ 162.30099487]), [164.320007]),\n",
       " (array([ 167.54418945]), [166.759995]),\n",
       " (array([ 169.32254028]), [165.58000200000001]),\n",
       " (array([ 167.53422546]), [169.13999899999999]),\n",
       " (array([ 171.565979]), [172.61999499999999]),\n",
       " (array([ 174.40786743]), [172.509995]),\n",
       " (array([ 173.46524048]), [171.91000400000001]),\n",
       " (array([ 172.79829407]), [170.33000200000001]),\n",
       " (array([ 171.24816895]), [166.979996]),\n",
       " (array([ 168.28390503]), [165.11000100000001]),\n",
       " (array([ 167.08935547]), [167.30999800000001]),\n",
       " (array([ 169.6395874]), [165.25]),\n",
       " (array([ 167.08651733]), [161.36999499999999]),\n",
       " (array([ 163.52719116]), [162.41999799999999]),\n",
       " (array([ 165.28135681]), [163.429993]),\n",
       " (array([ 165.95143127]), [167.240005]),\n",
       " (array([ 169.93304443]), [170.08999599999999]),\n",
       " (array([ 172.19189453]), [172.990005]),\n",
       " (array([ 174.56098938]), [173.13000500000001]),\n",
       " (array([ 173.98536682]), [174.720001]),\n",
       " (array([ 175.55770874]), [173.020004]),\n",
       " (array([ 173.37934875]), [168.61999499999999]),\n",
       " (array([ 169.41777039]), [169.33999599999999]),\n",
       " (array([ 171.07974243]), [174.509995]),\n",
       " (array([ 176.22679138]), [177.71000700000002]),\n",
       " (array([ 178.68315125]), [177.550003]),\n",
       " (array([ 177.54496765]), [179.16999799999999]),\n",
       " (array([ 179.29174805]), [174.86999499999999]),\n",
       " (array([ 174.29354858]), [173.28999299999998]),\n",
       " (array([ 173.75796509]), [174.740005]),\n",
       " (array([ 175.40187073]), [176.85000600000001]),\n",
       " (array([ 177.38375854]), [181.69000199999999]),\n",
       " (array([ 182.36038208]), [182.38999899999999]),\n",
       " (array([ 182.16212463]), [186.61999499999999]),\n",
       " (array([ 186.94767761]), [185.0]),\n",
       " (array([ 184.25740051]), [186.11999499999999]),\n",
       " (array([ 185.91755676]), [186.820007]),\n",
       " (array([ 186.41169739]), [190.529999]),\n",
       " (array([ 190.81352234]), [186.58999599999999]),\n",
       " (array([ 185.59487915]), [178.89999399999999]),\n",
       " (array([ 177.47486877]), [177.38999899999999]),\n",
       " (array([ 177.33435059]), [177.25]),\n",
       " (array([ 177.08343506]), [181.63000500000001]),\n",
       " (array([ 182.09457397]), [182.25]),\n",
       " (array([ 181.99168396]), [180.36000100000001]),\n",
       " (array([ 179.61053467]), [181.970001]),\n",
       " (array([ 181.85466003]), [185.88000500000001]),\n",
       " (array([ 186.06463623]), [187.449997]),\n",
       " (array([ 187.25085449]), [184.63000500000001]),\n",
       " (array([ 183.61865234]), [181.35000600000001]),\n",
       " (array([ 180.36703491]), [183.91999799999999]),\n",
       " (array([ 183.97293091]), [187.300003]),\n",
       " (array([ 187.40690613]), [186.38000500000001]),\n",
       " (array([ 185.72946167]), [187.320007]),\n",
       " (array([ 187.07270813]), [187.25]),\n",
       " (array([ 186.74868774]), [182.240005]),\n",
       " (array([ 180.86448669]), [183.35000600000001]),\n",
       " (array([ 183.28591919]), [187.38000500000001]),\n",
       " (array([ 187.58416748]), [187.35000600000001]),\n",
       " (array([ 186.9034729]), [188.75]),\n",
       " (array([ 188.60899353]), [186.61999499999999]),\n",
       " (array([ 185.79621887]), [185.729996]),\n",
       " (array([ 185.16381836]), [185.240005]),\n",
       " (array([ 184.62690735]), [181.479996]),\n",
       " (array([ 180.29333496]), [181.30999800000001]),\n",
       " (array([ 180.92358398]), [177.949997]),\n",
       " (array([ 177.05183411]), [177.05999800000001]),\n",
       " (array([ 176.92102051]), [182.21000700000002]),\n",
       " (array([ 182.81314087]), [180.94000199999999]),\n",
       " (array([ 180.46647644]), [188.0]),\n",
       " (array([ 189.15577698]), [189.449997]),\n",
       " (array([ 189.58854675]), [189.66000400000001]),\n",
       " (array([ 189.33366394]), [190.83999599999999]),\n",
       " (array([ 190.80020142]), [192.94000199999999]),\n",
       " (array([ 193.16644287]), [194.050003]),\n",
       " (array([ 194.23847961]), [191.58000200000001]),\n",
       " (array([ 191.20401001]), [194.55999800000001]),\n",
       " (array([ 195.42204285]), [192.179993]),\n",
       " (array([ 191.88467407]), [191.14999399999999]),\n",
       " (array([ 191.12762451]), [188.720001]),\n",
       " (array([ 188.16213989]), [187.479996]),\n",
       " (array([ 187.0324707]), [183.570007]),\n",
       " (array([ 182.40827942]), [182.88999899999999]),\n",
       " (array([ 182.38568115]), [187.240005]),\n",
       " (array([ 187.54985046]), [181.470001]),\n",
       " (array([ 180.11878967]), [182.03999299999998]),\n",
       " (array([ 182.08863831]), [184.75]),\n",
       " (array([ 184.66252136]), [184.949997]),\n",
       " (array([ 184.44042969]), [183.990005]),\n",
       " (array([ 183.28175354]), [186.179993]),\n",
       " (array([ 186.07312012]), [183.88000500000001]),\n",
       " (array([ 182.92913818]), [186.300003]),\n",
       " (array([ 186.35189819]), [185.53999299999998]),\n",
       " (array([ 184.86685181]), [184.66000400000001]),\n",
       " (array([ 183.99497986]), [182.53999299999998]),\n",
       " (array([ 181.62135315]), [181.58999599999999]),\n",
       " (array([ 180.94502258]), [181.30999800000001]),\n",
       " (array([ 180.76409912]), [182.320007]),\n",
       " (array([ 181.98272705]), [180.550003]),\n",
       " (array([ 179.7593689]), [179.16000400000001]),\n",
       " (array([ 178.62217712]), [180.0]),\n",
       " (array([ 179.78646851]), [181.070007]),\n",
       " (array([ 180.802948]), [180.520004]),\n",
       " (array([ 179.97918701]), [188.520004]),\n",
       " (array([ 189.77597046]), [189.979996]),\n",
       " (array([ 190.25521851]), [191.929993]),\n",
       " (array([ 192.01687622]), [191.729996]),\n",
       " (array([ 191.54838562]), [190.979996]),\n",
       " (array([ 190.76580811]), [190.46000700000002]),\n",
       " (array([ 190.27078247]), [192.5]),\n",
       " (array([ 192.79724121]), [192.60000600000001]),\n",
       " (array([ 192.55302429]), [192.61999499999999]),\n",
       " (array([ 192.64170837]), [191.529999]),\n",
       " (array([ 191.34532166]), [193.63999899999999]),\n",
       " (array([ 194.12492371]), [192.820007]),\n",
       " (array([ 192.7197876]), [193.35000600000001]),\n",
       " (array([ 193.58651733]), [192.949997]),\n",
       " (array([ 192.9695282]), [193.13000500000001]),\n",
       " (array([ 193.28163147]), [192.41999799999999]),\n",
       " (array([ 192.36636353]), [192.61999499999999]),\n",
       " (array([ 192.74200439]), [192.220001]),\n",
       " (array([ 192.17190552]), [192.25]),\n",
       " (array([ 192.28460693]), [193.020004]),\n",
       " (array([ 193.19012451]), [193.41999799999999]),\n",
       " (array([ 193.54638672]), [193.38999899999999]),\n",
       " (array([ 193.49014282]), [193.86999499999999]),\n",
       " (array([ 194.11184692]), [197.61000100000001]),\n",
       " (array([ 198.61016846]), [197.759995]),\n",
       " (array([ 198.29562378]), [197.529999]),\n",
       " (array([ 198.11581421]), [197.979996]),\n",
       " (array([ 198.81091309]), [196.729996]),\n",
       " (array([ 197.19004822]), [197.529999]),\n",
       " (array([ 198.43859863]), [198.80999800000001]),\n",
       " (array([ 199.75027466]), [200.66000400000001]),\n",
       " (array([ 201.82174683]), [197.259995]),\n",
       " (array([ 197.53440857]), [197.770004]),\n",
       " (array([ 199.00190735]), [199.80999800000001]),\n",
       " (array([ 201.03833008]), [200.61999499999999]),\n",
       " (array([ 201.647995]), [201.0]),\n",
       " (array([ 202.11010742]), [203.779999]),\n",
       " (array([ 205.55664062]), [204.720001]),\n",
       " (array([ 206.29992676]), [206.0]),\n",
       " (array([ 207.80078125]), [206.009995]),\n",
       " (array([ 207.72660828]), [205.720001]),\n",
       " (array([ 207.45648193]), [204.25]),\n",
       " (array([ 205.78372192]), [204.69000199999999]),\n",
       " (array([ 206.56851196]), [205.490005]),\n",
       " (array([ 207.32531738]), [205.479996]),\n",
       " (array([ 207.18026733]), [207.770004]),\n",
       " (array([ 209.92788696]), [207.179993]),\n",
       " (array([ 208.91879272]), [207.28999299999998]),\n",
       " (array([ 209.19520569]), [208.270004]),\n",
       " (array([ 210.30264282]), [208.64999399999999]),\n",
       " (array([ 210.58538818]), [209.470001]),\n",
       " (array([ 211.48080444]), [209.5]),\n",
       " (array([ 211.41165161]), [206.050003]),\n",
       " (array([ 207.48934937]), [205.470001]),\n",
       " (array([ 207.46447754]), [204.94000199999999]),\n",
       " (array([ 206.68525696]), [202.33000200000001]),\n",
       " (array([ 203.58071899]), [202.58000200000001]),\n",
       " (array([ 204.37413025]), [205.320007]),\n",
       " (array([ 207.36660767]), [202.800003]),\n",
       " (array([ 203.90777588]), [202.720001]),\n",
       " (array([ 204.41477966]), [207.449997]),\n",
       " (array([ 209.9286499]), [200.13000500000001]),\n",
       " (array([ 200.65029907]), [199.509995]),\n",
       " (array([ 201.58297729]), [199.60000600000001]),\n",
       " (array([ 200.84054565]), [198.61999499999999]),\n",
       " (array([ 199.41662598]), [200.0]),\n",
       " (array([ 201.30206299]), [203.570007]),\n",
       " (array([ 205.33236694]), [205.58000200000001]),\n",
       " (array([ 207.29217529]), [206.80999800000001]),\n",
       " (array([ 208.60028076]), [207.08000200000001]),\n",
       " (array([ 208.8896637]), [208.0]),\n",
       " (array([ 209.9914856]), [208.05999800000001]),\n",
       " (array([ 209.94177246]), [207.240005]),\n",
       " (array([ 209.0176239]), [204.990005]),\n",
       " (array([ 206.54058838]), [203.75]),\n",
       " (array([ 205.4440918]), [201.479996]),\n",
       " (array([ 202.75471497]), [201.229996]),\n",
       " (array([ 202.77801514]), [200.60000600000001]),\n",
       " (array([ 201.79882812]), [201.16999799999999]),\n",
       " (array([ 202.53927612]), [199.44000199999999]),\n",
       " (array([ 200.26928711]), [199.03999299999998]),\n",
       " (array([ 200.14622498]), [199.729996]),\n",
       " (array([ 200.90753174]), [197.88999899999999]),\n",
       " (array([ 198.46278381]), [195.88000500000001]),\n",
       " (array([ 196.39593506]), [197.759995]),\n",
       " (array([ 198.96676636]), [196.820007]),\n",
       " ...]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(predicted,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
