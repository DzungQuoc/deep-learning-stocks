{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2416,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas_datareader.data import DataReader\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2417,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading or downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2418,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_if_not_exists(force=False):\n",
    "    if os.path.exists(\"./data/ibm.csv\") and not force:\n",
    "        return pd.read_csv(\"./data/ibm.csv\")\n",
    "    else:\n",
    "        if not os.path.exists(\"./data\"):\n",
    "            os.mkdir(\"data\")\n",
    "        ibm_data = DataReader('IBM', 'yahoo', datetime(1950, 1, 1), datetime.today())\n",
    "        pd.DataFrame(ibm_data).to_csv(\"./data/ibm.csv\")\n",
    "        return pd.DataFrame(ibm_data).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the data\n",
      "done loading the data\n"
     ]
    }
   ],
   "source": [
    "print \"loading the data\"\n",
    "data = get_data_if_not_exists(force=True)\n",
    "print \"done loading the data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data columns names: ['Date' 'Open' 'High' 'Low' 'Close' 'Volume' 'Adj Close']\n"
     ]
    }
   ],
   "source": [
    "print \"data columns names: %s\"%data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13732, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1962-01-02</td>\n",
       "      <td>578.499734</td>\n",
       "      <td>578.499734</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>387200</td>\n",
       "      <td>2.300695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1962-01-03</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>288000</td>\n",
       "      <td>2.320804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962-01-04</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>570.999742</td>\n",
       "      <td>571.250260</td>\n",
       "      <td>256000</td>\n",
       "      <td>2.297679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1962-01-05</td>\n",
       "      <td>570.500243</td>\n",
       "      <td>570.500243</td>\n",
       "      <td>558.999753</td>\n",
       "      <td>560.000253</td>\n",
       "      <td>363200</td>\n",
       "      <td>2.252429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1962-01-08</td>\n",
       "      <td>559.500003</td>\n",
       "      <td>559.500003</td>\n",
       "      <td>545.000267</td>\n",
       "      <td>549.500263</td>\n",
       "      <td>544000</td>\n",
       "      <td>2.210196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Open        High         Low       Close  Volume  \\\n",
       "0 1962-01-02  578.499734  578.499734  572.000241  572.000241  387200   \n",
       "1 1962-01-03  572.000241  576.999736  572.000241  576.999736  288000   \n",
       "2 1962-01-04  576.999736  576.999736  570.999742  571.250260  256000   \n",
       "3 1962-01-05  570.500243  570.500243  558.999753  560.000253  363200   \n",
       "4 1962-01-08  559.500003  559.500003  545.000267  549.500263  544000   \n",
       "\n",
       "   Adj Close  \n",
       "0   2.300695  \n",
       "1   2.320804  \n",
       "2   2.297679  \n",
       "3   2.252429  \n",
       "4   2.210196  "
      ]
     },
     "execution_count": 2421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print data.shape\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "found out that Adj Close is not the last day close. it's the \"true\" close of the day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2422,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(1,len(data)):\n",
    "    prev = data.iloc[i-1]\n",
    "    data.set_value(i,\"prev_close\",prev[\"Close\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[\"up/down\"] = (data[\"Close\"] - data[\"prev_close\"]) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"raise_percentage\"] = (data[\"Close\"] - data[\"prev_close\"])/data[\"prev_close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2425,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"spread\"] = abs(data[\"High\"]-data[\"Low\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2426,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"up_spread\"] = abs(data[\"High\"]-data[\"Open\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2427,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"down_spread\"] = abs(data[\"Open\"]-data[\"Low\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "for i in range(1,len(data)):\n",
    "    prev = data.iloc[i-1]\n",
    "    data.set_value(i,\"prev_open\",prev[\"Open\"])\n",
    "    data.set_value(i,\"prev_high\",prev[\"High\"])\n",
    "    data.set_value(i,\"prev_low\",prev[\"Low\"])\n",
    "#     data.set_value(i,\"month\",re.findall(\"[1-9]+\", str(data.Date[i]))[2])\n",
    "#     data.set_value(i,\"year\",re.findall(\"[1-9]+\", str(data.Date[i]))[0])\n",
    "    \n",
    "#     prev = data.iloc[i-2]\n",
    "#     data.set_value(i,\"prev_prev_open\",prev[\"Open\"])\n",
    "#     data.set_value(i,\"prev_prev_high\",prev[\"High\"])\n",
    "#     data.set_value(i,\"prev_prev_low\",prev[\"Low\"])\n",
    "#     data.set_value(i,\"prev_prev_close\",prev[\"Close\"])\n",
    "\n",
    "data[\"close_diff\"] = abs(data[\"Close\"] - data[\"prev_close\"])\n",
    "# data[\"close_diff\"] = abs(data[\"Close\"] / data[\"prev_close\"])\n",
    "data[\"open_diff\"] = abs(data[\"Open\"] - data[\"prev_open\"])\n",
    "# data[\"open_diff\"] = abs(data[\"Open\"] / data[\"prev_open\"])\n",
    "data[\"high_diff\"] = abs(data[\"High\"] - data[\"prev_high\"])\n",
    "# data[\"high_diff\"] = abs(data[\"High\"] / data[\"prev_high\"])\n",
    "data[\"low_diff\"] = abs(data[\"Low\"] - data[\"prev_low\"])\n",
    "# data[\"low_diff\"] = abs(data[\"Low\"] / data[\"prev_low\"])\n",
    "\n",
    "# data[\"prev_prev_close_diff\"] = (data[\"Close\"] - data[\"prev_prev_close\"])\n",
    "# data[\"prev_prev_raise_percentage\"] = (data[\"Close\"] - data[\"prev_prev_close\"])/data[\"prev_prev_close\"]\n",
    "# data[\"prev_prev_open_diff\"] = (data[\"Open\"] - data[\"prev_prev_open\"])\n",
    "# data[\"prev_prev_high_diff\"] = (data[\"High\"] - data[\"prev_prev_high\"])\n",
    "# data[\"prev_prev_low_diff\"] = (data[\"Low\"] - data[\"prev_prev_low\"])\n",
    "# data[\"open_close_mean\"] = (data[\"Open\"] + data[\"Close\"])/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2429,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>prev_close</th>\n",
       "      <th>up/down</th>\n",
       "      <th>raise_percentage</th>\n",
       "      <th>spread</th>\n",
       "      <th>up_spread</th>\n",
       "      <th>down_spread</th>\n",
       "      <th>prev_open</th>\n",
       "      <th>prev_high</th>\n",
       "      <th>prev_low</th>\n",
       "      <th>close_diff</th>\n",
       "      <th>open_diff</th>\n",
       "      <th>high_diff</th>\n",
       "      <th>low_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1962-01-02</td>\n",
       "      <td>578.499734</td>\n",
       "      <td>578.499734</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>387200</td>\n",
       "      <td>2.300695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.499493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.499493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1962-01-03</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>288000</td>\n",
       "      <td>2.320804</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>True</td>\n",
       "      <td>0.008740</td>\n",
       "      <td>4.999495</td>\n",
       "      <td>4.999495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>578.499734</td>\n",
       "      <td>578.499734</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>4.999495</td>\n",
       "      <td>6.499493</td>\n",
       "      <td>1.499998</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962-01-04</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>570.999742</td>\n",
       "      <td>571.250260</td>\n",
       "      <td>256000</td>\n",
       "      <td>2.297679</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.009964</td>\n",
       "      <td>5.999994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.999994</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>5.749476</td>\n",
       "      <td>4.999495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1962-01-05</td>\n",
       "      <td>570.500243</td>\n",
       "      <td>570.500243</td>\n",
       "      <td>558.999753</td>\n",
       "      <td>560.000253</td>\n",
       "      <td>363200</td>\n",
       "      <td>2.252429</td>\n",
       "      <td>571.250260</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.019694</td>\n",
       "      <td>11.500490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.500490</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>570.999742</td>\n",
       "      <td>11.250007</td>\n",
       "      <td>6.499493</td>\n",
       "      <td>6.499493</td>\n",
       "      <td>11.999989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1962-01-08</td>\n",
       "      <td>559.500003</td>\n",
       "      <td>559.500003</td>\n",
       "      <td>545.000267</td>\n",
       "      <td>549.500263</td>\n",
       "      <td>544000</td>\n",
       "      <td>2.210196</td>\n",
       "      <td>560.000253</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.018750</td>\n",
       "      <td>14.499736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.499736</td>\n",
       "      <td>570.500243</td>\n",
       "      <td>570.500243</td>\n",
       "      <td>558.999753</td>\n",
       "      <td>10.499990</td>\n",
       "      <td>11.000240</td>\n",
       "      <td>11.000240</td>\n",
       "      <td>13.999486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Open        High         Low       Close  Volume  \\\n",
       "0 1962-01-02  578.499734  578.499734  572.000241  572.000241  387200   \n",
       "1 1962-01-03  572.000241  576.999736  572.000241  576.999736  288000   \n",
       "2 1962-01-04  576.999736  576.999736  570.999742  571.250260  256000   \n",
       "3 1962-01-05  570.500243  570.500243  558.999753  560.000253  363200   \n",
       "4 1962-01-08  559.500003  559.500003  545.000267  549.500263  544000   \n",
       "\n",
       "   Adj Close  prev_close up/down  raise_percentage     spread  up_spread  \\\n",
       "0   2.300695         NaN   False               NaN   6.499493   0.000000   \n",
       "1   2.320804  572.000241    True          0.008740   4.999495   4.999495   \n",
       "2   2.297679  576.999736   False         -0.009964   5.999994   0.000000   \n",
       "3   2.252429  571.250260   False         -0.019694  11.500490   0.000000   \n",
       "4   2.210196  560.000253   False         -0.018750  14.499736   0.000000   \n",
       "\n",
       "   down_spread   prev_open   prev_high    prev_low  close_diff  open_diff  \\\n",
       "0     6.499493         NaN         NaN         NaN         NaN        NaN   \n",
       "1     0.000000  578.499734  578.499734  572.000241    4.999495   6.499493   \n",
       "2     5.999994  572.000241  576.999736  572.000241    5.749476   4.999495   \n",
       "3    11.500490  576.999736  576.999736  570.999742   11.250007   6.499493   \n",
       "4    14.499736  570.500243  570.500243  558.999753   10.499990  11.000240   \n",
       "\n",
       "   high_diff   low_diff  \n",
       "0        NaN        NaN  \n",
       "1   1.499998   0.000000  \n",
       "2   0.000000   1.000499  \n",
       "3   6.499493  11.999989  \n",
       "4  11.000240  13.999486  "
      ]
     },
     "execution_count": 2429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removing the first record because have no previuse record therefore can't know if up or down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>prev_close</th>\n",
       "      <th>raise_percentage</th>\n",
       "      <th>spread</th>\n",
       "      <th>up_spread</th>\n",
       "      <th>down_spread</th>\n",
       "      <th>prev_open</th>\n",
       "      <th>prev_high</th>\n",
       "      <th>prev_low</th>\n",
       "      <th>close_diff</th>\n",
       "      <th>open_diff</th>\n",
       "      <th>high_diff</th>\n",
       "      <th>low_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13731.000000</td>\n",
       "      <td>13731.000000</td>\n",
       "      <td>13731.000000</td>\n",
       "      <td>13731.000000</td>\n",
       "      <td>1.373100e+04</td>\n",
       "      <td>13731.000000</td>\n",
       "      <td>13731.000000</td>\n",
       "      <td>13731.000000</td>\n",
       "      <td>13731.000000</td>\n",
       "      <td>13731.000000</td>\n",
       "      <td>13731.000000</td>\n",
       "      <td>13731.000000</td>\n",
       "      <td>13731.000000</td>\n",
       "      <td>13731.000000</td>\n",
       "      <td>13731.000000</td>\n",
       "      <td>13731.000000</td>\n",
       "      <td>13731.000000</td>\n",
       "      <td>13731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>190.029059</td>\n",
       "      <td>191.625164</td>\n",
       "      <td>188.532009</td>\n",
       "      <td>190.054171</td>\n",
       "      <td>4.888342e+06</td>\n",
       "      <td>42.175604</td>\n",
       "      <td>190.084077</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>3.093155</td>\n",
       "      <td>1.596105</td>\n",
       "      <td>1.497050</td>\n",
       "      <td>190.059539</td>\n",
       "      <td>191.655518</td>\n",
       "      <td>188.562043</td>\n",
       "      <td>2.016392</td>\n",
       "      <td>1.946078</td>\n",
       "      <td>1.744849</td>\n",
       "      <td>1.822445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>132.133261</td>\n",
       "      <td>132.918323</td>\n",
       "      <td>131.463776</td>\n",
       "      <td>132.141526</td>\n",
       "      <td>4.578848e+06</td>\n",
       "      <td>51.413127</td>\n",
       "      <td>132.181493</td>\n",
       "      <td>0.019022</td>\n",
       "      <td>2.525031</td>\n",
       "      <td>1.927112</td>\n",
       "      <td>1.955795</td>\n",
       "      <td>132.174593</td>\n",
       "      <td>132.959075</td>\n",
       "      <td>131.504268</td>\n",
       "      <td>4.575595</td>\n",
       "      <td>4.471322</td>\n",
       "      <td>4.482632</td>\n",
       "      <td>4.527691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>40.625000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.231153</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-0.749178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>40.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>97.500000</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>97.449997</td>\n",
       "      <td>1.182200e+06</td>\n",
       "      <td>5.943053</td>\n",
       "      <td>97.449997</td>\n",
       "      <td>-0.007978</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.269997</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.379997</td>\n",
       "      <td>0.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>128.000000</td>\n",
       "      <td>129.125000</td>\n",
       "      <td>127.139999</td>\n",
       "      <td>128.210007</td>\n",
       "      <td>4.172100e+06</td>\n",
       "      <td>16.207522</td>\n",
       "      <td>128.210007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>129.125000</td>\n",
       "      <td>127.139999</td>\n",
       "      <td>1.180008</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>263.812550</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>263.999996</td>\n",
       "      <td>6.966700e+06</td>\n",
       "      <td>71.055749</td>\n",
       "      <td>263.999998</td>\n",
       "      <td>0.008337</td>\n",
       "      <td>3.875054</td>\n",
       "      <td>2.030003</td>\n",
       "      <td>1.999647</td>\n",
       "      <td>263.875020</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>2.499924</td>\n",
       "      <td>2.375046</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>2.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>649.000015</td>\n",
       "      <td>649.874802</td>\n",
       "      <td>645.500031</td>\n",
       "      <td>649.000015</td>\n",
       "      <td>6.944470e+07</td>\n",
       "      <td>197.047189</td>\n",
       "      <td>649.000015</td>\n",
       "      <td>0.131636</td>\n",
       "      <td>42.000031</td>\n",
       "      <td>28.500009</td>\n",
       "      <td>42.000031</td>\n",
       "      <td>649.000015</td>\n",
       "      <td>649.874802</td>\n",
       "      <td>645.500031</td>\n",
       "      <td>308.499985</td>\n",
       "      <td>309.000015</td>\n",
       "      <td>311.500015</td>\n",
       "      <td>312.999992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open          High           Low         Close        Volume  \\\n",
       "count  13731.000000  13731.000000  13731.000000  13731.000000  1.373100e+04   \n",
       "mean     190.029059    191.625164    188.532009    190.054171  4.888342e+06   \n",
       "std      132.133261    132.918323    131.463776    132.141526  4.578848e+06   \n",
       "min       41.000000     41.750000     40.625000     41.000000  0.000000e+00   \n",
       "25%       97.500000     98.500000     96.500000     97.449997  1.182200e+06   \n",
       "50%      128.000000    129.125000    127.139999    128.210007  4.172100e+06   \n",
       "75%      263.812550    266.000000    262.000000    263.999996  6.966700e+06   \n",
       "max      649.000015    649.874802    645.500031    649.000015  6.944470e+07   \n",
       "\n",
       "          Adj Close    prev_close  raise_percentage        spread  \\\n",
       "count  13731.000000  13731.000000      13731.000000  13731.000000   \n",
       "mean      42.175604    190.084077          0.000131      3.093155   \n",
       "std       51.413127    132.181493          0.019022      2.525031   \n",
       "min        1.231153     41.000000         -0.749178      0.000000   \n",
       "25%        5.943053     97.449997         -0.007978      1.500000   \n",
       "50%       16.207522    128.210007          0.000000      2.375000   \n",
       "75%       71.055749    263.999998          0.008337      3.875054   \n",
       "max      197.047189    649.000015          0.131636     42.000031   \n",
       "\n",
       "          up_spread   down_spread     prev_open     prev_high      prev_low  \\\n",
       "count  13731.000000  13731.000000  13731.000000  13731.000000  13731.000000   \n",
       "mean       1.596105      1.497050    190.059539    191.655518    188.562043   \n",
       "std        1.927112      1.955795    132.174593    132.959075    131.504268   \n",
       "min        0.000000      0.000000     41.000000     41.750000     40.625000   \n",
       "25%        0.375000      0.269997     97.500000     98.500000     96.500000   \n",
       "50%        1.000000      0.875000    128.000000    129.125000    127.139999   \n",
       "75%        2.030003      1.999647    263.875020    266.000000    262.000000   \n",
       "max       28.500009     42.000031    649.000015    649.874802    645.500031   \n",
       "\n",
       "         close_diff     open_diff     high_diff      low_diff  \n",
       "count  13731.000000  13731.000000  13731.000000  13731.000000  \n",
       "mean       2.016392      1.946078      1.744849      1.822445  \n",
       "std        4.575595      4.471322      4.482632      4.527691  \n",
       "min        0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.500000      0.500000      0.379997      0.400002  \n",
       "50%        1.180008      1.125000      1.000000      1.000000  \n",
       "75%        2.499924      2.375046      2.062500      2.187500  \n",
       "max      308.499985    309.000015    311.500015    312.999992  "
      ]
     },
     "execution_count": 2430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[1:]\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2431,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_WINDOW = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(items):\n",
    "    return [[item[1], item[2], item[3], item[4],\n",
    "            item[5], item[6], item[9], item[10],\n",
    "            item[11], item[12], \n",
    "            item[16], item[17],\n",
    "            item[18], item[19],\n",
    "             1] \n",
    "            \n",
    "            if item[8] \n",
    "            \n",
    "            else \n",
    "           [item[1], item[2], item[3], item[4],\n",
    "            item[5], item[6], item[9], item[10],\n",
    "            item[11], item[12], \n",
    "            item[16], item[17],\n",
    "            item[18], item[19],\n",
    "             0] \n",
    "            \n",
    "            for item in items]\n",
    "                \n",
    "\n",
    "# def extract_features(items):\n",
    "#     return [[item[12],item[11],item[10],item[9], 1] if item[8] else [item[12],item[11],item[10],item[9], -1] for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2433,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_expected_result(item):\n",
    "    return 1 if item[8] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2434,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_input_and_outputs(data):\n",
    "    step = 1\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for i in range(0, len(data) - MAX_WINDOW, step):\n",
    "        inputs.append(extract_features(data.iloc[i:i + MAX_WINDOW].as_matrix()))\n",
    "        outputs.append(extract_expected_result(data.iloc[i + MAX_WINDOW].as_matrix()))\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2435,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating model input and outputs\n",
      "done generating input and outputs\n"
     ]
    }
   ],
   "source": [
    "print \"generating model input and outputs\"\n",
    "X, y = generate_input_and_outputs(data)\n",
    "print \"done generating input and outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the data to train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2438,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_validation,y_train,y_validation = train_test_split(X_train,y_train,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configure the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2439,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2440,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_output_size1 = 5\n",
    "layer_output_size2 = 5\n",
    "number_of_features = 1\n",
    "output_classes = len(y[0])\n",
    "percentage_of_neurons_to_ignore = 0.2\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(layer_output_size1, return_sequences=True, input_shape=(MAX_WINDOW, len(X[0][0]))))\n",
    "model.add(Dropout(percentage_of_neurons_to_ignore))\n",
    "model.add(LSTM(layer_output_size2, return_sequences=False))\n",
    "model.add(Dropout(percentage_of_neurons_to_ignore))\n",
    "model.add(Dense(output_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.alg_name = \"lstm\"\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='rmsprop')\n",
    "models.append(model)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(layer_output_size1, return_sequences=True, input_shape=(MAX_WINDOW, len(X[0][0]))))\n",
    "model.add(Dropout(percentage_of_neurons_to_ignore))\n",
    "model.add(SimpleRNN(layer_output_size2, return_sequences=False))\n",
    "model.add(Dropout(percentage_of_neurons_to_ignore))\n",
    "model.add(Dense(output_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.alg_name = \"simpleRnn\"\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='rmsprop')\n",
    "models.append(model)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(layer_output_size1, return_sequences=True, input_shape=(MAX_WINDOW, len(X[0][0]))))\n",
    "model.add(Dropout(percentage_of_neurons_to_ignore))\n",
    "model.add(GRU(layer_output_size2, return_sequences=False))\n",
    "model.add(Dropout(percentage_of_neurons_to_ignore))\n",
    "model.add(Dense(output_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.alg_name = \"gru\"\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='rmsprop')\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainModel(model):\n",
    "    epochs = 1\n",
    "    print \"Training model %s\"%(model.alg_name)\n",
    "    model.fit(X_train, y_train, batch_size=128, nb_epoch=epochs,validation_data=(X_validation,y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2442,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createSplit(model):\n",
    "    split_model = RandomForestClassifier()\n",
    "    split_model.fit(model.predict(X_validation), y_validation)\n",
    "    return split_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2443,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probabilities_to_prediction(record):\n",
    "    return [1,0] if record[0]>record[1] else [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2444,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluateModel(model):\n",
    "    success, success2 = 0,0\n",
    "    predicts = model.predict(X_test)\n",
    "    split_model = createSplit(model)\n",
    "    for index, record in enumerate(predicts):\n",
    "        predicted = list(split_model.predict([np.array(record)])[0])\n",
    "        predicted2 = probabilities_to_prediction(record)\n",
    "        expected = y_test[index]\n",
    "        if predicted[0] == expected[0]:\n",
    "            success += 1\n",
    "        if predicted2[0] == expected[0]:\n",
    "            success2 += 1\n",
    "    accuracy = float(success) / len(predicts)\n",
    "    accuracy2 = float(success2) / len(predicts)\n",
    "    print \"The Accuracy for %s is: %s or %s\" % (model.alg_name, accuracy, accuracy2)\n",
    "    return accuracy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(epochs):\n",
    "    accuracies = {}\n",
    "    for i in range(epochs):\n",
    "        print \"Epoch %s\"%(i)\n",
    "        for model in models:\n",
    "            trainModel(model)\n",
    "            acc = evaluateModel(model)\n",
    "            if model.alg_name not in accuracies:\n",
    "                accuracies[model.alg_name] = []\n",
    "            accuracies[model.alg_name].append(acc)\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6934 - acc: 0.5028 - val_loss: 0.6927 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6932 - acc: 0.5095 - val_loss: 0.6922 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.51693989071 or 0.51621129326\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5088 - val_loss: 0.6924 - val_acc: 0.5241\n",
      "The Accuracy for gru is: 0.51693989071 or 0.51621129326\n",
      "Epoch 1\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5139 - val_loss: 0.6922 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6933 - acc: 0.5089 - val_loss: 0.6923 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.51621129326 or 0.51621129326\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5105 - val_loss: 0.6923 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.517304189435 or 0.51693989071\n",
      "Epoch 2\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6932 - acc: 0.5018 - val_loss: 0.6923 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5112 - val_loss: 0.6926 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.51621129326 or 0.51621129326\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5087 - val_loss: 0.6922 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.517304189435 or 0.51693989071\n",
      "Epoch 3\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6932 - acc: 0.5096 - val_loss: 0.6924 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5062 - val_loss: 0.6926 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.517304189435 or 0.51621129326\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5047 - val_loss: 0.6924 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.517304189435 or 0.517304189435\n",
      "Epoch 4\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5062 - val_loss: 0.6922 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5067 - val_loss: 0.6927 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.51693989071 or 0.516575591985\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5088 - val_loss: 0.6925 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.51693989071 or 0.517304189435\n",
      "Epoch 5\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6934 - acc: 0.5065 - val_loss: 0.6924 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5097 - val_loss: 0.6924 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.517304189435 or 0.516575591985\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5052 - val_loss: 0.6924 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.51693989071 or 0.51693989071\n",
      "Epoch 6\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5100 - val_loss: 0.6924 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6933 - acc: 0.5063 - val_loss: 0.6924 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.517304189435 or 0.51621129326\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5077 - val_loss: 0.6923 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.517304189435 or 0.517304189435\n",
      "Epoch 7\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5127 - val_loss: 0.6926 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5089 - val_loss: 0.6927 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.51621129326 or 0.515846994536\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5092 - val_loss: 0.6925 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.517304189435 or 0.517304189435\n",
      "Epoch 8\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6934 - acc: 0.5055 - val_loss: 0.6924 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6925 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.51621129326 or 0.51621129326\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5073 - val_loss: 0.6923 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.517304189435 or 0.517304189435\n",
      "Epoch 9\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5077 - val_loss: 0.6922 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5103 - val_loss: 0.6928 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.517304189435 or 0.51621129326\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5096 - val_loss: 0.6923 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.517304189435 or 0.517304189435\n",
      "Epoch 10\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6933 - acc: 0.5022 - val_loss: 0.6922 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6924 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.517304189435 or 0.51621129326\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6929 - acc: 0.5091 - val_loss: 0.6923 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.517304189435 or 0.517304189435\n",
      "Epoch 11\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5116 - val_loss: 0.6924 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6929 - acc: 0.5051 - val_loss: 0.6925 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.517304189435 or 0.51621129326\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5102 - val_loss: 0.6925 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.517304189435 or 0.517304189435\n",
      "Epoch 12\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6933 - acc: 0.5063 - val_loss: 0.6926 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6933 - acc: 0.5079 - val_loss: 0.6925 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.516575591985 or 0.51621129326\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5084 - val_loss: 0.6923 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.517304189435 or 0.517304189435\n",
      "Epoch 13\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5094 - val_loss: 0.6923 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5089 - val_loss: 0.6925 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.516575591985 or 0.51621129326\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5085 - val_loss: 0.6925 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.517304189435 or 0.517304189435\n",
      "Epoch 14\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6932 - acc: 0.5046 - val_loss: 0.6923 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5091 - val_loss: 0.6923 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.51621129326 or 0.51621129326\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5071 - val_loss: 0.6923 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.517304189435 or 0.517304189435\n",
      "Epoch 15\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6932 - acc: 0.5061 - val_loss: 0.6923 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6932 - acc: 0.5092 - val_loss: 0.6925 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.517304189435 or 0.51621129326\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6929 - acc: 0.5109 - val_loss: 0.6922 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.517304189435 or 0.517304189435\n",
      "Epoch 16\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6934 - acc: 0.5038 - val_loss: 0.6922 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5072 - val_loss: 0.6927 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.517304189435 or 0.51621129326\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5109 - val_loss: 0.6923 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.517304189435 or 0.517304189435\n",
      "Epoch 17\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5091 - val_loss: 0.6928 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5088 - val_loss: 0.6926 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.517304189435 or 0.516575591985\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5111 - val_loss: 0.6922 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.517304189435 or 0.517304189435\n",
      "Epoch 18\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6933 - acc: 0.5055 - val_loss: 0.6925 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6932 - acc: 0.5059 - val_loss: 0.6928 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.517304189435 or 0.516575591985\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5094 - val_loss: 0.6924 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.51693989071 or 0.51693989071\n",
      "Epoch 19\n",
      "Training model lstm\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6932 - acc: 0.5083 - val_loss: 0.6924 - val_acc: 0.5241\n",
      "The Accuracy for lstm is: 0.51621129326 or 0.51621129326\n",
      "Training model simpleRnn\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6925 - val_acc: 0.5241\n",
      "The Accuracy for simpleRnn is: 0.517304189435 or 0.51621129326\n",
      "Training model gru\n",
      "Train on 8783 samples, validate on 2196 samples\n",
      "Epoch 1/1\n",
      "8783/8783 [==============================] - 0s - loss: 0.6930 - acc: 0.5098 - val_loss: 0.6923 - val_acc: 0.5246\n",
      "The Accuracy for gru is: 0.51693989071 or 0.517304189435\n"
     ]
    }
   ],
   "source": [
    "accs = train_and_evaluate(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy for lstm is 0.51621129326\n",
      "the accuracy for gru is 0.517176684882\n",
      "the accuracy for simpleRnn is 0.516265938069\n"
     ]
    }
   ],
   "source": [
    "for algo in accs:\n",
    "    print \"the accuracy for %s is %s\"%(algo,sum(accs[algo])/len(accs[algo]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
