{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning on IBM Stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "We choose to analyse IBM history stock data which include about 13K records from the last 54 years. [From the year 1962 to this day]\n",
    "Each record contains:  \n",
    "- Open price: The price in which the market in that month started at.\n",
    "- Close price: The price in which the market in that month closed at.\n",
    "- High Price: The max price the stock reached within the month.\n",
    "- Low price: The min price the stock reached within the month.\n",
    "- Volume: The max price the stock reached within the month.\n",
    "- [Adjacent close price](https://marubozu.blogspot.co.il/2006/09/how-yahoo-calculates-adjusted-closing.html).  \n",
    "- Date: Day, Month and Year.\n",
    "\n",
    "The main challenges of this project are: \n",
    "- The limited data within a market that is changed by wide variety of things. In particular, things that we don't see in the raw data, like special accouncments on new technology.\n",
    "- The historic data of stocks in a particular situation doesn't necessarily resolve the same outcome in the exact same situation a few years later.\n",
    "- We wondered whether it is possible to actually find some features that will give us better accuracy than random.  \n",
    "\n",
    "This project is interesting because as everybody knows deep learning solved tasks that considered difficult even with pretty basic deep learning features.  \n",
    "\n",
    "\n",
    "And of course, If we find something useful when it comes to stock then good prediction = profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from pandas_datareader.data import DataReader\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load or Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_if_not_exists(force=False):\n",
    "    if os.path.exists(\"./data/ibm.csv\") and not force:\n",
    "        return pd.read_csv(\"./data/ibm.csv\")\n",
    "    else:\n",
    "        if not os.path.exists(\"./data\"):\n",
    "            os.mkdir(\"data\")\n",
    "        ibm_data = DataReader('IBM', 'yahoo', datetime(1950, 1, 1), datetime.today())\n",
    "        pd.DataFrame(ibm_data).to_csv(\"./data/ibm.csv\")\n",
    "        return pd.DataFrame(ibm_data).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the data\n",
      "done loading the data\n"
     ]
    }
   ],
   "source": [
    "print \"loading the data\"\n",
    "data = get_data_if_not_exists(force=True)\n",
    "print \"done loading the data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data columns names: ['Date' 'Open' 'High' 'Low' 'Close' 'Volume' 'Adj Close']\n"
     ]
    }
   ],
   "source": [
    "print \"data columns names: %s\"%data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13743, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1962-01-02</td>\n",
       "      <td>578.499734</td>\n",
       "      <td>578.499734</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>387200</td>\n",
       "      <td>2.300695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1962-01-03</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>572.000241</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>288000</td>\n",
       "      <td>2.320804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962-01-04</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>576.999736</td>\n",
       "      <td>570.999742</td>\n",
       "      <td>571.250260</td>\n",
       "      <td>256000</td>\n",
       "      <td>2.297679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1962-01-05</td>\n",
       "      <td>570.500243</td>\n",
       "      <td>570.500243</td>\n",
       "      <td>558.999753</td>\n",
       "      <td>560.000253</td>\n",
       "      <td>363200</td>\n",
       "      <td>2.252429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1962-01-08</td>\n",
       "      <td>559.500003</td>\n",
       "      <td>559.500003</td>\n",
       "      <td>545.000267</td>\n",
       "      <td>549.500263</td>\n",
       "      <td>544000</td>\n",
       "      <td>2.210196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Open        High         Low       Close  Volume  \\\n",
       "0 1962-01-02  578.499734  578.499734  572.000241  572.000241  387200   \n",
       "1 1962-01-03  572.000241  576.999736  572.000241  576.999736  288000   \n",
       "2 1962-01-04  576.999736  576.999736  570.999742  571.250260  256000   \n",
       "3 1962-01-05  570.500243  570.500243  558.999753  560.000253  363200   \n",
       "4 1962-01-08  559.500003  559.500003  545.000267  549.500263  544000   \n",
       "\n",
       "   Adj Close  \n",
       "0   2.300695  \n",
       "1   2.320804  \n",
       "2   2.297679  \n",
       "3   2.252429  \n",
       "4   2.210196  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print data.shape\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data exploration highlights:\n",
    "- The data contains 13,733 records.\n",
    "- Each record reprsent one specific day.\n",
    "- Each record contain: Date, Open, High, Low, Close, Volume and Adj Close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction and Data Pre-processing.\n",
    "\n",
    "#### The features are:\n",
    "1. Open price within the day.\n",
    "1. Highest price within the day.\n",
    "1. Lowest price within the day.\n",
    "1. Close price within the day.\n",
    "1. Adj Close.\n",
    "1. Raise percentage.\n",
    "1. Spread.\n",
    "1. Up Spread.\n",
    "1. Down Spread.\n",
    "1. Absolute Difference between Close and Previous day close.\n",
    "1. Absolute Difference between Open and Previous day open.\n",
    "1. Absolute Difference between High and Previous day high.\n",
    "1. Absolute Difference between low and Previous day low.\n",
    "1. For each day we've also added a 7 previous day sliding window containing all of the above.\n",
    "1. 1 When the stock price raised for that day, 0 When the stock price didn't raise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,len(data)):\n",
    "    prev = data.iloc[i-1]\n",
    "    data.set_value(i,\"prev_close\",prev[\"Close\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[\"up/down\"] = (data[\"Close\"] - data[\"prev_close\"]) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"raise_percentage\"] = (data[\"Close\"] - data[\"prev_close\"])/data[\"prev_close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"spread\"] = abs(data[\"High\"]-data[\"Low\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"up_spread\"] = abs(data[\"High\"]-data[\"Open\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"down_spread\"] = abs(data[\"Open\"]-data[\"Low\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "for i in range(1,len(data)):\n",
    "    prev = data.iloc[i-1]\n",
    "    data.set_value(i,\"prev_open\",prev[\"Open\"])\n",
    "    data.set_value(i,\"prev_high\",prev[\"High\"])\n",
    "    data.set_value(i,\"prev_low\",prev[\"Low\"])\n",
    "#     data.set_value(i,\"month\",re.findall(\"[1-9]+\", str(data.Date[i]))[2])\n",
    "#     data.set_value(i,\"year\",re.findall(\"[1-9]+\", str(data.Date[i]))[0])\n",
    "    \n",
    "#     prev = data.iloc[i-2]\n",
    "#     data.set_value(i,\"prev_prev_open\",prev[\"Open\"])\n",
    "#     data.set_value(i,\"prev_prev_high\",prev[\"High\"])\n",
    "#     data.set_value(i,\"prev_prev_low\",prev[\"Low\"])\n",
    "#     data.set_value(i,\"prev_prev_close\",prev[\"Close\"])\n",
    "\n",
    "data[\"close_diff\"] = abs(data[\"Close\"] - data[\"prev_close\"])\n",
    "# data[\"close_diff\"] = data[\"Close\"] - data[\"prev_close\"]\n",
    "# data[\"close_diff\"] = abs(data[\"Close\"] / data[\"prev_close\"])\n",
    "data[\"open_diff\"] = abs(data[\"Open\"] - data[\"prev_open\"])\n",
    "# data[\"open_diff\"] = data[\"Open\"] - data[\"prev_open\"]\n",
    "# data[\"open_diff\"] = abs(data[\"Open\"] / data[\"prev_open\"])\n",
    "data[\"high_diff\"] = abs(data[\"High\"] - data[\"prev_high\"])\n",
    "# data[\"high_diff\"] = data[\"High\"] - data[\"prev_high\"]\n",
    "# data[\"high_diff\"] = abs(data[\"High\"] / data[\"prev_high\"])\n",
    "data[\"low_diff\"] = abs(data[\"Low\"] - data[\"prev_low\"])\n",
    "# data[\"low_diff\"] = data[\"Low\"] - data[\"prev_low\"]\n",
    "# data[\"low_diff\"] = abs(data[\"Low\"] / data[\"prev_low\"])\n",
    "\n",
    "# data[\"prev_prev_close_diff\"] = (data[\"Close\"] - data[\"prev_prev_close\"])\n",
    "# data[\"prev_prev_raise_percentage\"] = (data[\"Close\"] - data[\"prev_prev_close\"])/data[\"prev_prev_close\"]\n",
    "# data[\"prev_prev_open_diff\"] = (data[\"Open\"] - data[\"prev_prev_open\"])\n",
    "# data[\"prev_prev_high_diff\"] = (data[\"High\"] - data[\"prev_prev_high\"])\n",
    "# data[\"prev_prev_low_diff\"] = (data[\"Low\"] - data[\"prev_prev_low\"])\n",
    "# data[\"open_close_mean\"] = (data[\"Open\"] + data[\"Close\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>prev_close</th>\n",
       "      <th>raise_percentage</th>\n",
       "      <th>spread</th>\n",
       "      <th>up_spread</th>\n",
       "      <th>down_spread</th>\n",
       "      <th>prev_open</th>\n",
       "      <th>prev_high</th>\n",
       "      <th>prev_low</th>\n",
       "      <th>close_diff</th>\n",
       "      <th>open_diff</th>\n",
       "      <th>high_diff</th>\n",
       "      <th>low_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13742.000000</td>\n",
       "      <td>13742.000000</td>\n",
       "      <td>13742.000000</td>\n",
       "      <td>13742.000000</td>\n",
       "      <td>1.374200e+04</td>\n",
       "      <td>13742.000000</td>\n",
       "      <td>13742.000000</td>\n",
       "      <td>13742.000000</td>\n",
       "      <td>13742.000000</td>\n",
       "      <td>13742.000000</td>\n",
       "      <td>13742.000000</td>\n",
       "      <td>13742.000000</td>\n",
       "      <td>13742.000000</td>\n",
       "      <td>13742.000000</td>\n",
       "      <td>13742.000000</td>\n",
       "      <td>13742.000000</td>\n",
       "      <td>13742.000000</td>\n",
       "      <td>13742.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>190.006037</td>\n",
       "      <td>191.601465</td>\n",
       "      <td>188.509573</td>\n",
       "      <td>190.031231</td>\n",
       "      <td>4.886938e+06</td>\n",
       "      <td>42.271036</td>\n",
       "      <td>190.061100</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>3.091893</td>\n",
       "      <td>1.595429</td>\n",
       "      <td>1.496464</td>\n",
       "      <td>190.036428</td>\n",
       "      <td>191.631796</td>\n",
       "      <td>188.539545</td>\n",
       "      <td>2.015346</td>\n",
       "      <td>1.945042</td>\n",
       "      <td>1.743851</td>\n",
       "      <td>1.821383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>132.082868</td>\n",
       "      <td>132.867750</td>\n",
       "      <td>131.413538</td>\n",
       "      <td>132.091112</td>\n",
       "      <td>4.577435e+06</td>\n",
       "      <td>51.503041</td>\n",
       "      <td>132.131071</td>\n",
       "      <td>0.019015</td>\n",
       "      <td>2.524436</td>\n",
       "      <td>1.926515</td>\n",
       "      <td>1.955146</td>\n",
       "      <td>132.124203</td>\n",
       "      <td>132.908490</td>\n",
       "      <td>131.454026</td>\n",
       "      <td>4.573926</td>\n",
       "      <td>4.469693</td>\n",
       "      <td>4.480986</td>\n",
       "      <td>4.526041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>40.625000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.231153</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-0.749178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>40.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>97.539997</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>1.182400e+06</td>\n",
       "      <td>5.944636</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>-0.007973</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.270004</td>\n",
       "      <td>97.539997</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.379997</td>\n",
       "      <td>0.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>128.125000</td>\n",
       "      <td>129.250000</td>\n",
       "      <td>127.209999</td>\n",
       "      <td>128.250000</td>\n",
       "      <td>4.168200e+06</td>\n",
       "      <td>16.215748</td>\n",
       "      <td>128.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>128.125000</td>\n",
       "      <td>129.250000</td>\n",
       "      <td>127.209999</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>263.750069</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>261.750092</td>\n",
       "      <td>263.750092</td>\n",
       "      <td>6.962825e+06</td>\n",
       "      <td>71.178575</td>\n",
       "      <td>263.843779</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>3.875046</td>\n",
       "      <td>2.029999</td>\n",
       "      <td>1.999498</td>\n",
       "      <td>263.750092</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>261.750092</td>\n",
       "      <td>2.499848</td>\n",
       "      <td>2.375046</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>2.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>649.000015</td>\n",
       "      <td>649.874802</td>\n",
       "      <td>645.500031</td>\n",
       "      <td>649.000015</td>\n",
       "      <td>6.944470e+07</td>\n",
       "      <td>197.047189</td>\n",
       "      <td>649.000015</td>\n",
       "      <td>0.131636</td>\n",
       "      <td>42.000031</td>\n",
       "      <td>28.500009</td>\n",
       "      <td>42.000031</td>\n",
       "      <td>649.000015</td>\n",
       "      <td>649.874802</td>\n",
       "      <td>645.500031</td>\n",
       "      <td>308.499985</td>\n",
       "      <td>309.000015</td>\n",
       "      <td>311.500015</td>\n",
       "      <td>312.999992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open          High           Low         Close        Volume  \\\n",
       "count  13742.000000  13742.000000  13742.000000  13742.000000  1.374200e+04   \n",
       "mean     190.006037    191.601465    188.509573    190.031231  4.886938e+06   \n",
       "std      132.082868    132.867750    131.413538    132.091112  4.577435e+06   \n",
       "min       41.000000     41.750000     40.625000     41.000000  0.000000e+00   \n",
       "25%       97.539997     98.500000     96.500000     97.500000  1.182400e+06   \n",
       "50%      128.125000    129.250000    127.209999    128.250000  4.168200e+06   \n",
       "75%      263.750069    266.000000    261.750092    263.750092  6.962825e+06   \n",
       "max      649.000015    649.874802    645.500031    649.000015  6.944470e+07   \n",
       "\n",
       "          Adj Close    prev_close  raise_percentage        spread  \\\n",
       "count  13742.000000  13742.000000      13742.000000  13742.000000   \n",
       "mean      42.271036    190.061100          0.000131      3.091893   \n",
       "std       51.503041    132.131071          0.019015      2.524436   \n",
       "min        1.231153     41.000000         -0.749178      0.000000   \n",
       "25%        5.944636     97.500000         -0.007973      1.500000   \n",
       "50%       16.215748    128.250000          0.000000      2.375000   \n",
       "75%       71.178575    263.843779          0.008313      3.875046   \n",
       "max      197.047189    649.000015          0.131636     42.000031   \n",
       "\n",
       "          up_spread   down_spread     prev_open     prev_high      prev_low  \\\n",
       "count  13742.000000  13742.000000  13742.000000  13742.000000  13742.000000   \n",
       "mean       1.595429      1.496464    190.036428    191.631796    188.539545   \n",
       "std        1.926515      1.955146    132.124203    132.908490    131.454026   \n",
       "min        0.000000      0.000000     41.000000     41.750000     40.625000   \n",
       "25%        0.375000      0.270004     97.539997     98.500000     96.500000   \n",
       "50%        1.000000      0.875000    128.125000    129.250000    127.209999   \n",
       "75%        2.029999      1.999498    263.750092    266.000000    261.750092   \n",
       "max       28.500009     42.000031    649.000015    649.874802    645.500031   \n",
       "\n",
       "         close_diff     open_diff     high_diff      low_diff  \n",
       "count  13742.000000  13742.000000  13742.000000  13742.000000  \n",
       "mean       2.015346      1.945042      1.743851      1.821383  \n",
       "std        4.573926      4.469693      4.480986      4.526041  \n",
       "min        0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.500000      0.500000      0.379997      0.400002  \n",
       "50%        1.180000      1.125000      1.000000      1.000000  \n",
       "75%        2.499848      2.375046      2.062500      2.187500  \n",
       "max      308.499985    309.000015    311.500015    312.999992  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing the first record because have no previuse record therefore can't know if up or down\n",
    "data = data[1:]\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_WINDOW = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(items):\n",
    "    return [[item[1], item[2], item[3], item[4],\n",
    "            item[5], item[6], item[9], item[10],\n",
    "            item[11], item[12], item[16], item[17],\n",
    "            item[18], item[19], 1] \n",
    "            \n",
    "            if item[8] \n",
    "            \n",
    "            else \n",
    "           [item[1], item[2], item[3], item[4],\n",
    "            item[5], item[6], item[9], item[10],\n",
    "            item[11], item[12], item[16], item[17],\n",
    "            item[18], item[19], 0] \n",
    "            \n",
    "            for item in items]\n",
    "                \n",
    "\n",
    "# def extract_features(items):\n",
    "#     return [[item[12],item[11],item[10],item[9], 1] if item[8] else [item[12],item[11],item[10],item[9], -1] for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_expected_result(item):\n",
    "    return 1 if item[8] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_input_and_outputs(data,extractFeaturesFunc=extract_features,expectedResultFunc=extract_expected_result):\n",
    "    step = 1\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for i in range(0, len(data) - MAX_WINDOW, step):\n",
    "        inputs.append(extractFeaturesFunc(data.iloc[i:i + MAX_WINDOW].as_matrix()))\n",
    "        outputs.append(expectedResultFunc(data.iloc[i + MAX_WINDOW].as_matrix()))\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"generating model input and outputs\"\n",
    "X, y = generate_input_and_outputs(data)\n",
    "print \"done generating input and outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_validation,y_train,y_validation = train_test_split(X_train,y_train,test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration of the deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_output_size1 = 128\n",
    "layer_output_size2 = 128\n",
    "output_classes = len(y[0])\n",
    "percentage_of_neurons_to_ignore = 0.2\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(layer_output_size1, return_sequences=True, input_shape=(MAX_WINDOW, len(X[0][0]))))\n",
    "model.add(Dropout(percentage_of_neurons_to_ignore))\n",
    "model.add(LSTM(layer_output_size2, return_sequences=False))\n",
    "model.add(Dropout(percentage_of_neurons_to_ignore))\n",
    "model.add(Dense(output_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.alg_name = \"LSTM\"\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='rmsprop')\n",
    "models.append(model)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(layer_output_size1, return_sequences=True, input_shape=(MAX_WINDOW, len(X[0][0]))))\n",
    "model.add(Dropout(percentage_of_neurons_to_ignore))\n",
    "model.add(SimpleRNN(layer_output_size2, return_sequences=False))\n",
    "model.add(Dropout(percentage_of_neurons_to_ignore))\n",
    "model.add(Dense(output_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.alg_name = \"SimpleRNN\"\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='rmsprop')\n",
    "models.append(model)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(layer_output_size1, return_sequences=True, input_shape=(MAX_WINDOW, len(X[0][0]))))\n",
    "model.add(Dropout(percentage_of_neurons_to_ignore))\n",
    "model.add(GRU(layer_output_size2, return_sequences=False))\n",
    "model.add(Dropout(percentage_of_neurons_to_ignore))\n",
    "model.add(Dense(output_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.alg_name = \"GRU\"\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='rmsprop')\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainModel(model):\n",
    "    epochs = 5\n",
    "    print \"Training model %s\"%(model.alg_name)\n",
    "    model.fit(X_train, y_train, batch_size=128, nb_epoch=epochs,validation_data=(X_validation,y_validation), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def createSplit(model):\n",
    "    print 'Adding layer of DecisionTreeClassifier'\n",
    "#     split_model = RandomForestClassifier()\n",
    "#     split_model.fit(model.predict(X_validation), y_validation)\n",
    "    \n",
    "#     split_model = ExtraTreesClassifier(n_estimators=15, max_depth=None, min_samples_split=2, random_state=0)\n",
    "#     split_model.fit(model.predict(X_validation), y_validation)\n",
    "    \n",
    "#     split_model = DecisionTreeClassifier(max_depth=None, min_samples_split=1, random_state=0)\n",
    "#     split_model.fit(model.predict(X_validation), y_validation)\n",
    "    \n",
    "    split_model = DecisionTreeClassifier()\n",
    "    split_model.fit(model.predict(X_validation), y_validation)\n",
    "    return split_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probabilities_to_prediction(record):\n",
    "    return [1,0] if record[0]>record[1] else [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluateModel(model):\n",
    "    success, success2 = 0,0\n",
    "    predicts = model.predict(X_test)\n",
    "    split_model = createSplit(model)\n",
    "    for index, record in enumerate(predicts):\n",
    "        predicted = list(split_model.predict([np.array(record)])[0])\n",
    "        predicted2 = probabilities_to_prediction(record)\n",
    "        expected = y_test[index]\n",
    "        if predicted[0] == expected[0]:\n",
    "            success += 1\n",
    "        if predicted2[0] == expected[0]:\n",
    "            success2 += 1\n",
    "    accuracy = float(success) / len(predicts)\n",
    "    accuracy2 = float(success2) / len(predicts)\n",
    "    print \"The Accuracy for %s is: %s\" % (model.alg_name, max(accuracy2, accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate():\n",
    "    accuracies = {}\n",
    "    for model in models:\n",
    "        trainModel(model)\n",
    "        acc = evaluateModel(model)\n",
    "        if model.alg_name not in accuracies:\n",
    "            accuracies[model.alg_name] = []\n",
    "        accuracies[model.alg_name].append(acc)\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = train_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive algorithm:\n",
    "\n",
    "We'll choose the most frequent up / down of the stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = data[\"up/down\"].count()\n",
    "most_frequent = data[\"up/down\"].describe().top\n",
    "frequency = data[\"up/down\"].describe().freq\n",
    "acc = float(frequency) / all_data\n",
    "\n",
    "print 'The most frequent is: %s' % (most_frequent) \n",
    "print 'The accuracy of naive algorithm is: ', acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Evaluation analysis:\n",
    "\n",
    "#### Evaluation process:\n",
    "Our evaluation used two different configurations:\n",
    "1. Raw Deep-Learning algorithm.\n",
    "1. Deep-Learning algorithm With added layer of DecisionTreeClassifier.\n",
    "\n",
    "In both cases we used the predictions of the algorithm to create a sequence to tell us whether the stock is going to get up or down. Then we checked it with the actual data and calculated accuracy.\n",
    "\n",
    "### Results:\n",
    "The accuracy as stated above is better then a naive algorithm, Not by far, But still better which means that if we follow the algorithm we are actually expected to make profit.\n",
    "\n",
    "### What next?\n",
    "As expected it seems like the raw stock data isn't get a high estimation of the stock behavior.\n",
    "We could try mixing it with information from financial articles and news,  try to take into account related stocks like the sector, S&P500 and  new features,  even checking for a country specific economics laws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Creating sequence of close price from the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features2(items):\n",
    "    return [[item[4]] for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_expected_result2(item):\n",
    "    return [item[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_WINDOW = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(data, test_size=0.1):\n",
    "    \"\"\"\n",
    "    This just splits data to training and testing parts\n",
    "    \"\"\"\n",
    "    ntrn = int(round(len(data) * (1 - test_size)))\n",
    "    X, y = generate_input_and_outputs(data,extract_features2,extract_expected_result2)\n",
    "    X_train,y_train,X_test, y_test = X[:ntrn],y[:ntrn],X[ntrn:],y[ntrn:]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train,y_train, X_test, y_test = train_test_split(data,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_output_size1 = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(layer_output_size1, return_sequences=False, input_shape=(MAX_WINDOW, len(X_train[0][0]))))\n",
    "model.add(Dense(len(y_train[0]), input_dim=layer_output_size1))\n",
    "model.add(Activation(\"linear\"))\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=700, nb_epoch=500, validation_split=0.15,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip(predicted,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
